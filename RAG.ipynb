{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d7d071a-daf7-40dc-a652-860a71a06fd8",
   "metadata": {},
   "source": [
    "# Task List\n",
    "- structured intput and output for context compression\n",
    "- GPT3.5 LLM evaluator for grading context relevance is inaccurate\n",
    "- was cleaning up code and adding comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6c287f-3b06-4b73-8b54-87a893580a60",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaac6de6-2ef6-4586-9184-8d93a3990363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "from typing import List\n",
    "from datetime import datetime\n",
    "from operator import itemgetter\n",
    "from typing import Optional\n",
    "from _global import path_to_resources, hf_embed\n",
    "import templates\n",
    "\n",
    "from langchain.callbacks.tracers import LangChainTracer\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers.string import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "import langsmith\n",
    "from langsmith import traceable, trace\n",
    "from langsmith.evaluation import LangChainStringEvaluator, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca634257-130b-4d4b-8f7f-0e8425dd5d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up retriever\n",
    "db = Chroma(collection_name=\"main_collection\", persist_directory=f\"{path_to_resources}/db_main\", embedding_function=hf_embed)\n",
    "retriever = db.as_retriever(\n",
    "                search_type = \"similarity\",\n",
    "                search_kwargs = {\"k\":4},\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6392a02-2836-4da9-b7c1-8c4193b6952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langsmith setup\n",
    "project_name = \"ED-handout\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9732bba5-125c-43c1-94b3-5f35c6158a0f",
   "metadata": {},
   "source": [
    "# RAG Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "923bdf8f-201c-43dd-99ec-b23423c4fd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompressedDoc(BaseModel):\n",
    "    \"\"\"Represents a single compressed document containing relevant information extracted for a specific query.\"\"\"\n",
    "    id: int = Field(description=\"The unique identifier for the document, representing its position in the retrieval sequence.\")\n",
    "    context: str = Field(description=\"The relevant text extracted verbatim from the document. Special characters are properly escaped.\")\n",
    "    source: Optional[str] = Field(description=\"Source of the information\")\n",
    "\n",
    "    @validator('context')\n",
    "    def escape_special_characters(cls, value):\n",
    "        return json.dumps(value)[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df3e8183-f0f7-44ce-9522-97b256466816",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompressedDocs(BaseModel):\n",
    "    \"\"\"Represents a collection of compressed documents, all containing relevant information extracted for a specific query. Use by PydanticOutputParser tool.\"\"\"\n",
    "    contexts: List[CompressedDoc] = Field(description=\"A list of CompressedDoc objects, each representing a compressed document with extracted relevant information.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b228d657-be08-4d01-94af-fa08b78d3bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RagBot:\n",
    "    \"\"\"Bot that handles different steps of RAG\"\"\"\n",
    "    def __init__(self, retriever, templates, model: str = \"gpt-3.5-turbo-1106\"):\n",
    "        self._retriever = retriever\n",
    "        self._llm_gpt = ChatOpenAI(model_name=model, temperature=0)\n",
    "        self._llm_compressor = self._llm_gpt.with_structured_output(CompressedDocs)\n",
    "        self._llm_llama = Ollama(model=\"llama2:13b\", temperature=0)\n",
    "        self.templates = templates\n",
    "        self.queries = {\n",
    "            \"definition\": \"definition of {diagnosis}\",\n",
    "            \"presentation\": \"manifestations of {diagnosis}\",\n",
    "            \"course\": \"natural history of {diagnosis}\",\n",
    "            \"management\": \"treatment and management for {diagnosis}\",\n",
    "            \"follow_up\": \"follow-up plan for {diagnosis}\",\n",
    "            \"redflags\": \"signs and symptoms that indicate the need for urgent medical attention for patients with {diagnosis}\",\n",
    "        }\n",
    "\n",
    "    \n",
    "    @traceable\n",
    "    def diagnosis_extraction(self, assessment):\n",
    "        \"\"\"Extracts diagnosis from physician's assessment of the patient\"\"\"\n",
    "        prompt_extract_diagnosis = ChatPromptTemplate.from_messages([\n",
    "            (\"system\",self.templates.extract_diagnosis_system),\n",
    "            (\"human\", \"{assessment}\")\n",
    "        ])\n",
    "        chain_diagnosis = prompt_extract_diagnosis | self._llm_gpt\n",
    "        \n",
    "        return chain_diagnosis.invoke({\"assessment\":assessment}).content\n",
    "\n",
    "    \n",
    "    def make_queries(self, diagnosis):\n",
    "        \"\"\"Uses the diagnosis to populate dict of queries that will be used to retreive context from db\"\"\"\n",
    "        return {key: value.format(diagnosis=diagnosis) for key, value in self.queries.items()}\n",
    "\n",
    "    \n",
    "    @traceable(run_type=\"retriever\")\n",
    "    def _retrieve_docs(self, query):\n",
    "        return self._retriever.invoke(query)\n",
    "\n",
    "    \n",
    "    def get_contexts(self, queries):\n",
    "        \"\"\"returns dict with tuples of (query, contexts)\"\"\"\n",
    "        contexts = {}\n",
    "        for k, query in queries.items():\n",
    "            contexts[k] = (query, self._retrieve_docs(query))\n",
    "        \n",
    "        return contexts\n",
    "\n",
    "\n",
    "    def compress_contexts(self, q_c):\n",
    "        \"\"\"contextual compression with llm\"\"\"\n",
    "        prompt_compress = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", self.templates.compress_context_system),\n",
    "            (\"human\", self.templates.compress_context_human)\n",
    "        ])\n",
    "        chain_compress = prompt_compress | self._llm_compressor\n",
    "\n",
    "        return chain_compress.invoke({\"query\": q_c[0], \"context\": q_c[1]})\n",
    "\n",
    "    \n",
    "    @traceable()\n",
    "    def retrieval_steps(self, assessment):\n",
    "        \"\"\"all the steps to prep the contexts for final handout generation\"\"\"    \n",
    "        diagnosis = self.diagnosis_extraction(assessment)\n",
    "        queries = self.make_queries(diagnosis)\n",
    "        contexts = self.get_contexts(queries)\n",
    "\n",
    "        return {\"contexts\": contexts, \"diagnosis\": diagnosis}\n",
    "        \n",
    "    \n",
    "    @traceable()\n",
    "    def make_handout(self, assessment, md_plan):\n",
    "        _run_input = self.retrieval_steps(assessment)\n",
    "        _contexts = _run_input[\"contexts\"]\n",
    "        diagnosis = _run_input[\"diagnosis\"]\n",
    "\n",
    "        # compression\n",
    "        contexts = {}\n",
    "        for k, q_c in _contexts.items():\n",
    "            time.sleep(60)\n",
    "            contexts[k] = self.compress_contexts(q_c)\n",
    "        \n",
    "        # make handout\n",
    "        time.sleep(60)\n",
    "        prompt_make_handout = ChatPromptTemplate.from_messages([\n",
    "            (\"system\",self.templates.handout_generation_system),\n",
    "            (\"human\", self.templates.handout_generation_human),\n",
    "        ])\n",
    "        chain_make_handout = prompt_make_handout | self._llm_gpt\n",
    "        response = chain_make_handout.invoke({\n",
    "            \"context_definition\": contexts[\"definition\"],\n",
    "            \"context_presentation\": contexts[\"presentation\"],\n",
    "            \"context_course\": contexts[\"course\"],\n",
    "            \"context_management\": contexts[\"management\"],\n",
    "            \"context_follow_up\": contexts[\"follow_up\"],\n",
    "            \"context_redflags\": contexts[\"redflags\"],\n",
    "            \"context_md_plan\": md_plan,\n",
    "        })\n",
    "        \n",
    "        # Evaluators will expect \"answer\" and \"contexts\"\n",
    "        contexts_in_string = []\n",
    "        for arr in contexts.values():\n",
    "            contexts_in_string.append(\"\\n\".join([doc.context for doc in arr.contexts]))\n",
    "        contexts_in_string = \"\\n\\n\".join(contexts_in_string) + \"\\n\" + md_plan\n",
    "        \n",
    "        return {\n",
    "            \"diagnosis\": diagnosis,\n",
    "            \"contexts\": contexts_in_string,\n",
    "            \"handout\": response.content\n",
    "        }\n",
    "\n",
    "    @traceable()\n",
    "    def compression(self, assessment):\n",
    "        _run_input = self.retrieval_steps(assessment)\n",
    "        _contexts = _run_input[\"contexts\"]\n",
    "        diagnosis = _run_input[\"diagnosis\"]\n",
    "\n",
    "        # compression\n",
    "        contexts = {}\n",
    "        for k, q_c in _contexts.items():\n",
    "            contexts[k] = self.compress_contexts(q_c)\n",
    "\n",
    "        return contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0f810ed-9511-4576-b64d-67b34f25a759",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_bot = RagBot(retriever, templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c69f1239-4666-4f7c-a1a8-a634f77de00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith trace(\"Test compression output structure\", \"chain\", project_name=project_name, inputs=\"\") as rt:\\n    output = rag_bot.compression(\"7yo M with MSK injury - ankle sprain\")\\n    rt.end(outputs={\"output\": output})\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "with trace(\"Test compression output structure\", \"chain\", project_name=project_name, inputs=\"\") as rt:\n",
    "    output = rag_bot.compression(\"7yo M with MSK injury - ankle sprain\")\n",
    "    rt.end(outputs={\"output\": output})\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c55ef3f-50cd-4157-8f41-dac745b4cbde",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17fd4e5-11e3-437c-8c28-21ce3e3c2465",
   "metadata": {},
   "source": [
    "ways to use evaluations\n",
    "- to evaluate part of the RAG pipeline\n",
    "    1. **before handout generation**: this runs part of the rag pipeline -> create a dataset -> evaluate based on the data; used when optimizing each section (e.g prompt engineering, experimenting with retrieval strategies)\n",
    "    2. **after handout generation**: run on one example (dataset with assessment and plan as input for one diagnosis); used to test debug for individual case\n",
    "- evaluate the whole pipeline: run for all common diagnoses dataset (Pt_cases); evaluate the RAG chain on a database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0481bf51-268e-4417-adf2-c1ae7bc42c06",
   "metadata": {},
   "source": [
    "## Doc grader\n",
    "- given a diagnosis, create dataset of query + doc for each doc retrieved from each query\n",
    "- run experiement on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6887816a-7680-4cef-b0e5-a9fe19d2d267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\" Pydantic object used to format LLM output\n",
    "    * 0: irrelevant diagnosis \\n\n",
    "    * 1: correct diagnosis, but does not contain information to anser the user question \\n\n",
    "    * 2: correct diagnosis and contains information to answer the user question). \\n    \n",
    "    \"\"\"\n",
    "    score: str = Field(description=\"Documents grade based on correct diagnosis and relevant information\")\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "system = \"\"\"\n",
    "    You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    The content of the document can be found in page_content. Give a score for the document using the scoring system below. \n",
    "    Scoring: \n",
    "    * 0: irrelevant diagnosis \\n\n",
    "    * 1: correct diagnosis, but does not contain information to anser the user question \\n\n",
    "    * 2: correct diagnosis and contains information to answer the user question). \\n\n",
    "\"\"\"\n",
    "prompt_gradedoc = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"RETRIEVED DOCUMENT: \\n\\n {document} \\n\\n USER QUESTION: {query}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieval_grader = prompt_gradedoc | structured_llm_grader\n",
    "\n",
    "def grade_doc(query, doc) -> dict:\n",
    "    \"\"\"Grades one query and one corresponding document. used in eval type 3\"\"\"\n",
    "    grade = retrieval_grader.invoke({\"query\": query, \"document\": doc})\n",
    "    return {\"key\": \"grade\", \"score\": int(grade.score), \"comment\": \"grade for doc\"}\n",
    "\n",
    "def grade_docs(run, example) -> dict:\n",
    "    \"\"\"Grades all queries and corresponding documents in the db. used in eval type 1\"\"\"\n",
    "    grade = retrieval_grader.invoke({\"query\": example.inputs[\"query\"], \"document\": example.inputs[\"context\"]})\n",
    "    return {\"key\": \"grade\", \"score\": int(grade.score), \"comment\": \"grade for doc\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "479b7eb9-786a-4d54-b30f-b624f7cf5e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_relevance(diagnosis, context_dict, dataset_name):\n",
    "    \"\"\"Takes query_context dictionary and create a dataset for {diagnosis} to evaluate the relevance of retrieved context\"\"\"\n",
    "    client = langsmith.Client()\n",
    "    \n",
    "    dataset = client.create_dataset(\n",
    "        dataset_name=dataset_name,\n",
    "        description=f\"Test context relevance for docs retreiived for {diagnosis}\",\n",
    "    )\n",
    "\n",
    "    for query, q_c in context_dict.values(): #each document should be an example in the dataset        \n",
    "        for doc in q_c:\n",
    "            client.create_examples(\n",
    "                inputs=[{\"query\": query, \"context\": doc}],\n",
    "                dataset_id=dataset.id,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2d24128-e746-48bd-8ec9-e3e730a23097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval type: 1; used to asses the retrieved context's relevance\n",
    "\n",
    "def eval_context_relevance(rag_bot, assessment):\n",
    "    retrieved = rag_bot.retrieval_steps(assessment) # dict of query:context\n",
    "    context_dict = retrieved[\"contexts\"]\n",
    "    diagnosis = retrieved[\"diagnosis\"]\n",
    "\n",
    "    current_time = datetime.now().strftime('%Y-%m-%d, %H:%M:%S')\n",
    "    dataset_name = f\"Queries_Docs_{diagnosis}_{current_time}\"\n",
    "    create_dataset_relevance(diagnosis, context_dict, dataset_name)\n",
    "        \n",
    "    evaluate(\n",
    "        lambda x:x,\n",
    "        data=dataset_name,\n",
    "        evaluators=[grade_docs],\n",
    "        experiment_prefix=\"Context-relevance-\",\n",
    "        metadata={\n",
    "            \"model\": \"oai\",\n",
    "            \"diagnosis\":diagnosis\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c33348ea-1008-4e52-a7fb-6d4ff9882bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_context_relevance(rag_bot, \"5yo M, viral triggered asthma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feffa5be-acaa-4a9e-bb05-456b47c18b9b",
   "metadata": {},
   "source": [
    "## Faithful checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b4ec3cb-0292-4f9b-98a7-61f7713650e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not in use; used once to create dataset for eval_faithfulness_evaluator_prompt\n",
    "def create_dataset_faithfulness(handout, context, dataset_name):\n",
    "    \"\"\"Takes handout and contexts used to make a dataset\"\"\"\n",
    "    client = langsmith.Client()\n",
    "    \n",
    "    dataset = client.create_dataset(\n",
    "        dataset_name=dataset_name,\n",
    "        description=f\"Test whether handout for {diagnosis} is based on provided context\",\n",
    "    )\n",
    "\n",
    "    # **Preprocess context to remove headings\n",
    "    client.create_examples(\n",
    "        inputs=[{\"contexts\": contexts}],\n",
    "        outputs=[{\"handout\": handout}],\n",
    "        dataset_id=dataset.id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2a8f8bc-5f7e-49a6-a636-598a2694ecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Faithfulness(BaseModel):\n",
    "    \"\"\"List facts in handout not based on ground truth\"\"\"\n",
    "    list_of_false: List[str] = Field(description=\"List of facts in handout not based on ground truth\")\n",
    "\n",
    "# LLM with function call \n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(Faithfulness)\n",
    "\n",
    "# Prompt \n",
    "system = \"\"\"\n",
    "You are an expert assessor tasked with evaluating whether the generated text (provided by the user between the XML tags GENERATED TEXT) is factually based on the provided context (provided by the user between the XML tags CONTEXT).  \n",
    "\n",
    "Follow these steps:\n",
    "    Step 1: Read the provided context carefully. Understand the information presented in the context.\n",
    "    Step 2: Analyze each sentence in the GENERATED TEXT. Compare it with the provided CONTEXT to determine its factual basis. Sentences in the GENERATED TEXT that are similar (but not verbatim) to the sentences in provided CONTEXT, but are still factually aligned are considered factually based on the CONTEXT.\n",
    "    Step 3: Identify sentences in the GENERATED TEXT that are not factually based on the context (not factually supported by the provided CONTEXT or directly contradicts the provided CONTEXT.) \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "human = \"\"\"\n",
    "<GENERATED TEXT>\n",
    "{handout} \n",
    "</GENERATED TEXT>\n",
    "\n",
    "<CONTEXT>\n",
    "{contexts}\n",
    "</CONTEXT>\n",
    "\"\"\"\n",
    "\n",
    "prompt_faithfulness= ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", human),\n",
    "    ]\n",
    ")\n",
    "\n",
    "grader_faithfulness= prompt_faithfulness| structured_llm_grader\n",
    "\n",
    "def grade_faithfulness(run, example):\n",
    "    try: # try to get outputs from run, otherwise it is from dataset\n",
    "        handout = run.outputs[\"handout\"]\n",
    "        contexts = run.outputs[\"contexts\"]\n",
    "    except KeyError:\n",
    "        handout = example.outputs[\"handout\"]\n",
    "        contexts = example.inputs[\"contexts\"]\n",
    "        \n",
    "    result = grader_faithfulness.invoke({\"handout\": handout, \"contexts\": contexts}).list_of_false\n",
    "    count = len(result)\n",
    "    \n",
    "    return {\n",
    "        \"key\": \"count\", \"score\": count, \"comment\": \"num infactual sentences\",\n",
    "        \"sentences\": result\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cc83451-f127-4d4f-aca1-f4145f92f63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval type: 1; to experiment with prompt engineering for LLM evaluator using dataset on context and handout\n",
    "\n",
    "def eval_faithfulness_evaluator_prompt(rag_bot):\n",
    "    \"\"\"to evaluate prompt for LLM assessor for faithfulness evaluation task\"\"\"\n",
    "    dataset_name = \"Context_faithfulness\"\n",
    "        \n",
    "    evaluate(\n",
    "        lambda x:x,\n",
    "        data=dataset_name,\n",
    "        evaluators=[grade_faithfulness],\n",
    "        experiment_prefix=\"Faithfulness-prompt-\",\n",
    "        metadata={\n",
    "            \"model\": \"oai\",\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b130477-99a2-4507-8300-0201207474d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_faithfulness_evaluator_prompt(rag_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a281f1ae-a83f-4f24-86f1-7c3c57a3e026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval type: 2; to evaluate context faithfulness for one diagnosis by running the whole rag chain. No dataset created in this process\n",
    "def eval_context_faithfulness(rag_bot, assessment, md_plan):\n",
    "    evaluate(\n",
    "        lambda x: rag_bot.make_handout(assessment, md_plan),\n",
    "        data=\"Faithfulness\", # dummy dataset\n",
    "        evaluators=[grade_faithfulness],\n",
    "        experiment_prefix=\"Faithfulness-\",\n",
    "        metadata={\n",
    "            \"model\": \"oai\",\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "591ea43b-4f87-4d96-b002-6ea2fd7ea73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\neval_context_faithfulness(\\n    rag_bot,\\n    assessment=\"5yo M, first asthma exacerbation, virally triggered\", \\n    md_plan=\"-continue ventolin q4h \\n -continue flovent 125mcg qdaily \\n -follow-up with your family doctor in 2 days\",\\n)\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "eval_context_faithfulness(\n",
    "    rag_bot,\n",
    "    assessment=\"5yo M, first asthma exacerbation, virally triggered\", \n",
    "    md_plan=\"-continue ventolin q4h \\n -continue flovent 125mcg qdaily \\n -follow-up with your family doctor in 2 days\",\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935bf0de-f581-4c8b-92e0-ef0c53e562f5",
   "metadata": {},
   "source": [
    "## Full pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a90a08d-338a-421e-ab7a-c733dd222c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_relevance(root_run, example):\n",
    "    \"\"\"\n",
    "    A very simple evaluator that checks to see if the input of the retrieval step exists\n",
    "    in the retrieved docs.\n",
    "    \"\"\"\n",
    "    rag_pipeline_run = next(run for run in root_run.child_runs if run.name == \"make_handout\")\n",
    "    retrieve_run = next(run for run in rag_pipeline_run.child_runs if run.name == \"retrieval_steps\")\n",
    "\n",
    "    context_dict = retrieve_run.outputs[\"contexts\"]\n",
    "\n",
    "    scores = []\n",
    "    for query, q_c in context_dict.values(): #each document should be an example in the dataset        \n",
    "        for doc in q_c:\n",
    "            time.sleep(60)\n",
    "            scores.append(grade_doc(query, doc))\n",
    "            \n",
    "    return {\"results\": scores}\n",
    "    \n",
    "\n",
    "def faithfulness(root_run, example):\n",
    "    \"\"\"\n",
    "    A simple evaluator that checks to see the answer is grounded in the documents\n",
    "    \"\"\"\n",
    "    # Get documents and answer\n",
    "    rag_pipeline_run = next(run for run in root_run.child_runs if run.name == \"make_handout\")\n",
    "    time.sleep(60)\n",
    "    return grade_faithfulness(rag_pipeline_run, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "617e5b10-8f60-4c24-90f7-222fc7ed6bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_llm_allcases_1(rag_bot):\n",
    "    experiment_results = evaluate(\n",
    "        lambda inputs: rag_bot.make_handout(assessment=inputs[\"assessment\"], md_plan=inputs[\"plan\"]),\n",
    "        data=\"Dummy_pt_case\",\n",
    "        evaluators=[document_relevance, faithfulness],\n",
    "        experiment_prefix=datetime.now().strftime('%Y-%m-%d, %H:%M:%S')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee06f395-6eaf-4cad-87fd-cd5117941b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_llm_allcases_1(rag_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66492c7b-42d7-4e3c-8cab-c23f0986b01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_llm_allcases_2(rag_bot):\n",
    "    experiment_results = evaluate(\n",
    "        lambda inputs: rag_bot.make_handout(assessment=inputs[\"assessment\"], md_plan=inputs[\"plan\"]),\n",
    "        data=\"Pt_cases\",\n",
    "        evaluators=[document_relevance, faithfulness],\n",
    "        experiment_prefix=datetime.now().strftime('%Y-%m-%d, %H:%M:%S')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24e4f31d-e601-46f7-a6b1-f228e2729398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: '2024-06-25, 15:12:04-1841546d' at:\n",
      "https://smith.langchain.com/o/edfbc8bb-c3a3-5c1e-8b48-11b5a8cfd8ac/datasets/e3957f7c-e232-4541-beef-d7216ab12241/compare?selectedSessions=e9264028-60f4-4141-be52-7d72eac3ee61\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ad444ce3f44711ba1a5212c0695a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator document_relevance> on run 20005606-c32d-4674-9373-351077b7935f: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 59805, Requested 430. Please try again in 234ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/2776572676.py\", line 14, in document_relevance\n",
      "    scores.append(grade_doc(query, doc))\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/3432128128.py\", line 33, in grade_doc\n",
      "    grade = retrieval_grader.invoke({\"query\": query, \"document\": doc})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 2393, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 4427, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 170, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 599, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 456, in generate\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 446, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 671, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 522, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 590, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1240, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 921, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1020, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 59805, Requested 430. Please try again in 234ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator document_relevance> on run 760db76b-566d-42ed-870e-c3f776c90f06: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 59831, Requested 595. Please try again in 426ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/2776572676.py\", line 14, in document_relevance\n",
      "    scores.append(grade_doc(query, doc))\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/3432128128.py\", line 33, in grade_doc\n",
      "    grade = retrieval_grader.invoke({\"query\": query, \"document\": doc})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 2393, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 4427, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 170, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 599, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 456, in generate\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 446, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 671, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 522, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 590, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1240, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 921, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1020, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 59831, Requested 595. Please try again in 426ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator document_relevance> on run ca2e5776-fd5c-4720-af68-cdd2aac6dc3b: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 59679, Requested 761. Please try again in 440ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/2776572676.py\", line 14, in document_relevance\n",
      "    scores.append(grade_doc(query, doc))\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/3432128128.py\", line 33, in grade_doc\n",
      "    grade = retrieval_grader.invoke({\"query\": query, \"document\": doc})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 2393, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 4427, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 170, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 599, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 456, in generate\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 446, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 671, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 522, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 590, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1240, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 921, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1020, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 59679, Requested 761. Please try again in 440ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator document_relevance> on run 00f929a0-12e9-428a-9bbd-485871a0d717: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 59490, Requested 949. Please try again in 439ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/2776572676.py\", line 14, in document_relevance\n",
      "    scores.append(grade_doc(query, doc))\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/3432128128.py\", line 33, in grade_doc\n",
      "    grade = retrieval_grader.invoke({\"query\": query, \"document\": doc})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 2393, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 4427, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 170, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 599, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 456, in generate\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 446, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 671, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 522, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 590, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1240, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 921, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1020, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 59490, Requested 949. Please try again in 439ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator document_relevance> on run 38a046d2-7983-4ce9-bd4d-ac9b7c375e15: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 59563, Requested 934. Please try again in 497ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/2776572676.py\", line 14, in document_relevance\n",
      "    scores.append(grade_doc(query, doc))\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/3432128128.py\", line 33, in grade_doc\n",
      "    grade = retrieval_grader.invoke({\"query\": query, \"document\": doc})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 2393, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 4427, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 170, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 599, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 456, in generate\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 446, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 671, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 522, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 590, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1240, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 921, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1020, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 59563, Requested 934. Please try again in 497ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator document_relevance> on run f374871d-efd8-4931-bb2e-1cc980e2d058: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 59777, Requested 1118. Please try again in 895ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/2776572676.py\", line 14, in document_relevance\n",
      "    scores.append(grade_doc(query, doc))\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/3432128128.py\", line 33, in grade_doc\n",
      "    grade = retrieval_grader.invoke({\"query\": query, \"document\": doc})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 2393, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 4427, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 170, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 599, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 456, in generate\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 446, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 671, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 522, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 590, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1240, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 921, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1020, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 59777, Requested 1118. Please try again in 895ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator document_relevance> on run aa3cef21-e4c8-4e3e-84ac-d937c2d4b38e: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 59705, Requested 1189. Please try again in 894ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/2776572676.py\", line 14, in document_relevance\n",
      "    scores.append(grade_doc(query, doc))\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/3432128128.py\", line 33, in grade_doc\n",
      "    grade = retrieval_grader.invoke({\"query\": query, \"document\": doc})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 2393, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 4427, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 170, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 599, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 456, in generate\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 446, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 671, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 522, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 590, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1240, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 921, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1020, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 59705, Requested 1189. Please try again in 894ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator document_relevance> on run 6223c007-46b4-410e-82a6-edf5e347a23f: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 59662, Requested 1488. Please try again in 1.15s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/2776572676.py\", line 14, in document_relevance\n",
      "    scores.append(grade_doc(query, doc))\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/3432128128.py\", line 33, in grade_doc\n",
      "    grade = retrieval_grader.invoke({\"query\": query, \"document\": doc})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 2393, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 4427, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 170, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 599, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 456, in generate\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 446, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 671, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 522, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 590, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1240, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 921, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1020, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 59662, Requested 1488. Please try again in 1.15s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator faithfulness> on run 20005606-c32d-4674-9373-351077b7935f: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 59620, Requested 3640. Please try again in 3.26s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/2776572676.py\", line 26, in faithfulness\n",
      "    return grade_faithfulness(rag_pipeline_run, None)\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/371880261.py\", line 47, in grade_faithfulness\n",
      "    result = grader_faithfulness.invoke({\"handout\": handout, \"contexts\": contexts}).list_of_false\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 2393, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 4427, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 170, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 599, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 456, in generate\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 446, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 671, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 522, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 590, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1240, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 921, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1020, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 59620, Requested 3640. Please try again in 3.26s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator document_relevance> on run b467df8f-8d40-4f78-b790-7bac54e8ab8f: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 59731, Requested 844. Please try again in 575ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/2776572676.py\", line 14, in document_relevance\n",
      "    scores.append(grade_doc(query, doc))\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/3432128128.py\", line 33, in grade_doc\n",
      "    grade = retrieval_grader.invoke({\"query\": query, \"document\": doc})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 2393, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 4427, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 170, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 599, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 456, in generate\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 446, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 671, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 522, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 590, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1240, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 921, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1020, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 59731, Requested 844. Please try again in 575ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator faithfulness> on run 6223c007-46b4-410e-82a6-edf5e347a23f: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 59572, Requested 3372. Please try again in 2.944s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/2776572676.py\", line 26, in faithfulness\n",
      "    return grade_faithfulness(rag_pipeline_run, None)\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/371880261.py\", line 47, in grade_faithfulness\n",
      "    result = grader_faithfulness.invoke({\"handout\": handout, \"contexts\": contexts}).list_of_false\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 2393, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 4427, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 170, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 599, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 456, in generate\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 446, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 671, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 522, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 590, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1240, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 921, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1020, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 59572, Requested 3372. Please try again in 2.944s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator faithfulness> on run ca2e5776-fd5c-4720-af68-cdd2aac6dc3b: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 57920, Requested 4949. Please try again in 2.869s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/2776572676.py\", line 26, in faithfulness\n",
      "    return grade_faithfulness(rag_pipeline_run, None)\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/371880261.py\", line 47, in grade_faithfulness\n",
      "    result = grader_faithfulness.invoke({\"handout\": handout, \"contexts\": contexts}).list_of_false\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 2393, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 4427, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 170, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 599, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 456, in generate\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 446, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 671, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 522, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 590, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1240, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 921, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1020, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 57920, Requested 4949. Please try again in 2.869s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator faithfulness> on run 00f929a0-12e9-428a-9bbd-485871a0d717: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 56207, Requested 5823. Please try again in 2.03s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/2776572676.py\", line 26, in faithfulness\n",
      "    return grade_faithfulness(rag_pipeline_run, None)\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/371880261.py\", line 47, in grade_faithfulness\n",
      "    result = grader_faithfulness.invoke({\"handout\": handout, \"contexts\": contexts}).list_of_false\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 2393, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 4427, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 170, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 599, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 456, in generate\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 446, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 671, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 522, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 590, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1240, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 921, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1020, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 56207, Requested 5823. Please try again in 2.03s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator faithfulness> on run 38a046d2-7983-4ce9-bd4d-ac9b7c375e15: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 59023, Requested 6003. Please try again in 5.026s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/2776572676.py\", line 26, in faithfulness\n",
      "    return grade_faithfulness(rag_pipeline_run, None)\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/371880261.py\", line 47, in grade_faithfulness\n",
      "    result = grader_faithfulness.invoke({\"handout\": handout, \"contexts\": contexts}).list_of_false\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 2393, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 4427, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 170, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 599, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 456, in generate\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 446, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 671, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 522, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 590, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1240, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 921, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1020, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 59023, Requested 6003. Please try again in 5.026s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator faithfulness> on run f374871d-efd8-4931-bb2e-1cc980e2d058: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 59206, Requested 5841. Please try again in 5.047s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/2776572676.py\", line 26, in faithfulness\n",
      "    return grade_faithfulness(rag_pipeline_run, None)\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/371880261.py\", line 47, in grade_faithfulness\n",
      "    result = grader_faithfulness.invoke({\"handout\": handout, \"contexts\": contexts}).list_of_false\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 2393, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 4427, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 170, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 599, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 456, in generate\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 446, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 671, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 522, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 590, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1240, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 921, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1020, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 59206, Requested 5841. Please try again in 5.047s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator faithfulness> on run aa3cef21-e4c8-4e3e-84ac-d937c2d4b38e: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 56627, Requested 7165. Please try again in 3.792s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/2776572676.py\", line 26, in faithfulness\n",
      "    return grade_faithfulness(rag_pipeline_run, None)\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/371880261.py\", line 47, in grade_faithfulness\n",
      "    result = grader_faithfulness.invoke({\"handout\": handout, \"contexts\": contexts}).list_of_false\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 2393, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 4427, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 170, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 599, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 456, in generate\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 446, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 671, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 522, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 590, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1240, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 921, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1020, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 56627, Requested 7165. Please try again in 3.792s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator faithfulness> on run 760db76b-566d-42ed-870e-c3f776c90f06: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 56572, Requested 7785. Please try again in 4.357s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/2776572676.py\", line 26, in faithfulness\n",
      "    return grade_faithfulness(rag_pipeline_run, None)\n",
      "  File \"/var/folders/rc/1l8xrxl962j_sth8dsw54l6h0000gn/T/ipykernel_82422/371880261.py\", line 47, in grade_faithfulness\n",
      "    result = grader_faithfulness.invoke({\"handout\": handout, \"contexts\": contexts}).list_of_false\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 2393, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 4427, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 170, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 599, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 456, in generate\n",
      "    raise e\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 446, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 671, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 522, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 590, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1240, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 921, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py\", line 1020, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-hIcQ6WHRm8UbxJ53MIHwRhVG on tokens per min (TPM): Limit 60000, Used 56572, Requested 7785. Please try again in 4.357s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    }
   ],
   "source": [
    "eval_llm_allcases_2(rag_bot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fc3492-d5e1-426e-9428-01d2083cd48e",
   "metadata": {},
   "source": [
    "## LLM grading based on custom metrics\n",
    "- jargon\n",
    "- reference list\n",
    "- template format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5a519e-40f6-4cfd-b9f9-27cf48252fa7",
   "metadata": {},
   "source": [
    "## Human feedback of output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d593e441-f1d7-4521-96a2-ca060923a33d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
