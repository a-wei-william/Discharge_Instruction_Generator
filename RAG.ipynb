{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa6c287f-3b06-4b73-8b54-87a893580a60",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaac6de6-2ef6-4586-9184-8d93a3990363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from _global import path_to_resources, hf_embed\n",
    "import templates\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers.string import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "import langsmith\n",
    "from langsmith import traceable, trace\n",
    "from langsmith.evaluation import LangChainStringEvaluator, evaluate\n",
    "from langchain.callbacks.tracers import LangChainTracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca634257-130b-4d4b-8f7f-0e8425dd5d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up retriever\n",
    "db = Chroma(collection_name=\"main_collection\", persist_directory=f\"{path_to_resources}/db_wiki\", embedding_function=hf_embed)\n",
    "retriever = db.as_retriever(\n",
    "                search_type = \"similarity\",\n",
    "                search_kwargs = {\"k\":4},\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6392a02-2836-4da9-b7c1-8c4193b6952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langsmith setup\n",
    "project_name = \"ED-handout\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9732bba5-125c-43c1-94b3-5f35c6158a0f",
   "metadata": {},
   "source": [
    "# RAG Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b228d657-be08-4d01-94af-fa08b78d3bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RagBot:\n",
    "    def __init__(self, retriever, templates, model: str = \"gpt-3.5-turbo-1106\"):\n",
    "        self._retriever = retriever\n",
    "        self._llm_gpt = ChatOpenAI(model_name=model, temperature=0)\n",
    "        self._llm_llama = Ollama(model=\"llama2:13b\", temperature=0)\n",
    "        self.templates = templates\n",
    "        self.queries = {\n",
    "            \"definition\": \"definition of {diagnosis}\",\n",
    "            \"presentation\": \"manifestations of {diagnosis}\",\n",
    "            \"course\": \"natural history of {diagnosis}\",\n",
    "            \"management\": \"treatment and management for {diagnosis}\",\n",
    "            \"follow_up\": \"follow-up plan for {diagnosis}\",\n",
    "            \"redflags\": \"signs and symptoms that indicate the need for urgent medical attention for patients with {diagnosis}\",\n",
    "        }\n",
    "\n",
    "    \n",
    "    @traceable\n",
    "    def diagnosis_extraction(self, assessment):\n",
    "        \"\"\"Extracts diagnosis from physician's assessment of the patient\"\"\"\n",
    "        prompt_extract_diagnosis = ChatPromptTemplate.from_messages([\n",
    "            (\"system\",self.templates.extract_diagnosis_system),\n",
    "            (\"human\", \"{assessment}\")\n",
    "        ])\n",
    "        chain_diagnosis = prompt_extract_diagnosis | self._llm_gpt\n",
    "        \n",
    "        return chain_diagnosis.invoke({\"assessment\":assessment}).content\n",
    "\n",
    "    \n",
    "    def make_queries(self, diagnosis):\n",
    "        \"\"\"Uses the diagnosis to populate dict of queries that will be used to retreive context from db\"\"\"\n",
    "        return {key: value.format(diagnosis=diagnosis) for key, value in self.queries.items()}\n",
    "\n",
    "    \n",
    "    @traceable(run_type=\"retriever\")\n",
    "    def _retrieve_docs(self, query):\n",
    "        return self._retriever.invoke(query)\n",
    "\n",
    "    \n",
    "    def get_contexts(self, queries):\n",
    "        \"\"\"returns a tuple with (query, contexts)\"\"\"\n",
    "        contexts = {}\n",
    "        for k, query in queries.items():\n",
    "            contexts[k] = (query, self._retrieve_docs(query))\n",
    "        \n",
    "        return contexts\n",
    "\n",
    "\n",
    "    def compress_contexts(self, q_c):\n",
    "        prompt_compress = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", self.templates.compress_context_system),\n",
    "            (\"human\", self.templates.compress_context_human)\n",
    "        ])\n",
    "        chain_compress = prompt_compress | self._llm_gpt\n",
    "\n",
    "        return chain_compress.invoke({\"query\": q_c[0], \"context\": q_c[1]}).content\n",
    "\n",
    "    \n",
    "    @traceable()\n",
    "    def retrieval_steps(self, assessment):\n",
    "        \"\"\"All the steps to prep the contexts for final handout generation\"\"\"    \n",
    "        diagnosis = self.diagnosis_extraction(assessment)\n",
    "        queries = self.make_queries(diagnosis)\n",
    "        contexts = self.get_contexts(queries)\n",
    "\n",
    "        return {\"contexts\": contexts, \"diagnosis\": diagnosis}\n",
    "        \n",
    "    \n",
    "    @traceable()\n",
    "    def make_handout(self, assessment, md_plan):\n",
    "        _run_input = self.retrieval_steps(assessment)\n",
    "        _contexts = _run_input[\"contexts\"]\n",
    "        diagnosis = _run_input[\"diagnosis\"]\n",
    "\n",
    "        # compression\n",
    "        contexts = {}\n",
    "        for k, q_c in _contexts.items():\n",
    "            contexts[k] = self.compress_contexts(q_c)\n",
    "\n",
    "        # make handout\n",
    "        prompt_make_handout = ChatPromptTemplate.from_messages([\n",
    "            (\"system\",self.templates.handout_generation_system),\n",
    "            (\"human\", self.templates.handout_generation_human),\n",
    "        ])\n",
    "        chain_make_handout = prompt_make_handout | self._llm_gpt\n",
    "        response = chain_make_handout.invoke({\n",
    "            \"context_definition\": contexts[\"definition\"],\n",
    "            \"context_presentation\": contexts[\"presentation\"],\n",
    "            \"context_course\": contexts[\"course\"],\n",
    "            \"context_management\": contexts[\"management\"],\n",
    "            \"context_follow_up\": contexts[\"follow_up\"],\n",
    "            \"context_redflags\": contexts[\"redflags\"],\n",
    "            \"context_md_plan\": md_plan,\n",
    "        })\n",
    "        \n",
    "        # Evaluators will expect \"answer\" and \"contexts\"\n",
    "        return {\n",
    "            \"diagnosis\": diagnosis,\n",
    "            \"contexts\": \"\\n\".join(contexts.values()) + \"\\n\" + md_plan,\n",
    "            \"handout\": response.content,\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0f810ed-9511-4576-b64d-67b34f25a759",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = RagBot(retriever, templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffc37dd4-127c-4c5f-96db-89c1e8b85b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test that extraction works and works with langsmith\n",
    "\n",
    "with trace(\"Diagnosis extraction\", \"chain\", project_name=project_name, inputs={\"assessment\": \"5yo M with viral-triggered asthma\"}) as rt:\n",
    "    output = bot.diagnosis_extraction(inputs[\"assessment\"])\n",
    "    rt.end(outputs={\"output\": output})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3829b5a1-82c9-4d7a-81eb-765823dda5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to wrap the bot so it can be used with langsmith evaluate()\n",
    "def make_handout_with_context(rag_bot):\n",
    "    def _make_handout_with_context(example: dict):\n",
    "        \"\"\"Use this for evaluation of retrieved documents and hallucinations\"\"\"\n",
    "        response = rag_bot.make_handout(example[\"assessment\"], example[\"plan\"])\n",
    "        print(response)\n",
    "        return {\"handout\": response[\"handout\"], \"contexts\": response[\"contexts\"]}\n",
    "\n",
    "    return _make_handout_with_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c55ef3f-50cd-4157-8f41-dac745b4cbde",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0481bf51-268e-4417-adf2-c1ae7bc42c06",
   "metadata": {},
   "source": [
    "## Doc grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6887816a-7680-4cef-b0e5-a9fe19d2d267",
   "metadata": {},
   "outputs": [],
   "source": [
    "### OpenAI Grader\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# Data model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"0-2 score based on relevance of doc.\"\"\"\n",
    "\n",
    "    score: str = Field(description=\"Documents grade based on correct diagnosis and relevant information\")\n",
    "\n",
    "# LLM with function call \n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# Prompt \n",
    "system = \"\"\"\n",
    "    You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    The content of the document can be found in page_content. Give a score for the document using the scoring system below. \n",
    "    Scoring: \n",
    "    * 0: irrelevant diagnosis \\n\n",
    "    * 1: correct diagnosis, but does not contain information to anser the user question \\n\n",
    "    * 2: correct diagnosis and contains information to answer the user question). \\n\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "prompt_gradedoc = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"RETRIEVED DOCUMENT: \\n\\n {document} \\n\\n USER QUESTION: {query}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieval_grader = prompt_gradedoc | structured_llm_grader\n",
    "\n",
    "def grade_docs(run, example) -> dict:\n",
    "    grade = retrieval_grader.invoke({\"query\": example.inputs[\"query\"], \"document\": example.inputs[\"context\"]})\n",
    "    return {\"key\": \"grade\", \"score\": grade.score, \"comment\": \"grade for doc\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7769c3-2cc1-4bc9-96a6-078442e079c6",
   "metadata": {},
   "source": [
    "- given a diagnosis\n",
    "- create dataset of query + doc for each doc retrieved from each query\n",
    "- run experiement on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "479b7eb9-786a-4d54-b30f-b624f7cf5e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_relevance(diagnosis, context_dict, dataset_name):\n",
    "    \"\"\"Takes query_context dictionary and create a dataset for {diagnosis} to evaluate the relevance of retrieved context\"\"\"\n",
    "    client = langsmith.Client()\n",
    "    \n",
    "    dataset = client.create_dataset(\n",
    "        dataset_name=dataset_name,\n",
    "        description=f\"Test context relevance for docs retreiived for {diagnosis}\",\n",
    "    )\n",
    "\n",
    "    for query, q_c in context_dict.values(): #each document should be an example in the dataset        \n",
    "        for doc in q_c:\n",
    "            client.create_examples(\n",
    "                inputs=[{\"query\": query, \"context\": doc}],\n",
    "                dataset_id=dataset.id,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f2d24128-e746-48bd-8ec9-e3e730a23097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_relevance(rag_bot, assessment):\n",
    "    retrieved = rag_bot.retrieval_steps(assessment) # dict of query:context\n",
    "    context_dict = retrieved[\"contexts\"]\n",
    "    diagnosis = retrieved[\"diagnosis\"]\n",
    "\n",
    "    dataset_name = f\"Queries_Docs_{diagnosis}\"\n",
    "    #create_dataset_relevance(diagnosis, context_dict, dataset_name)\n",
    "        \n",
    "    evaluate(\n",
    "        lambda x:x,\n",
    "        data=dataset_name,\n",
    "        evaluators=[grade_docs],\n",
    "        experiment_prefix=\"Context-relevance-\",\n",
    "        metadata={\n",
    "            \"model\": \"oai\",\n",
    "            \"diagnosis\":diagnosis\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c33348ea-1008-4e52-a7fb-6d4ff9882bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'Context-relevance--ddec2471' at:\n",
      "https://smith.langchain.com/o/edfbc8bb-c3a3-5c1e-8b48-11b5a8cfd8ac/datasets/2c62c230-5ffb-4be1-a160-67b532c3d537/compare?selectedSessions=53cc885e-a871-4aa7-bf70-fa1cf31bdcd3\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de3554223a74b28a229995246a0335a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Document', 'metadata': {'Title': 'Acute severe asthma', 'source': 'https://en.wikipedia.org/wiki/Acute_severe_asthma', 'Header2': 'Recent research'}, 'page_content': 'A recent study proposed that the interaction between host airway epithelial cells and respiratory viruses is another aspect of innate immunity that is also a critical determination of asthma. It was also proposed that a rationale for how antiviral performance at the epithelial cell level might be improved to prevent acute infectious illness and chronic inflammatory disease caused by respiratory viruses.  \\nAnother study aimed to show that experimental asthma after viral infection inmate depended on Type I IFN-driven up-regulation of the high-affinity receptor for IgE \\\\(FcεRI\\\\) on conventional dendritic cells \\\\(cDCs\\\\) in the lungs. The study found that a Novell PMN-cDc interaction in the lung is necessary for a viral infection to induce atopic disease.'}{'type': 'Document', 'metadata': {'Title': 'Asthma', 'source': 'https://en.wikipedia.org/wiki/Asthma', 'Header2': 'Diagnosis', 'Header3': 'Classification', 'Header4': 'Infectious asthma'}, 'page_content': 'Infectious asthma is an easily identified clinical presentation. When queried, asthma patients may report that their first asthma symptoms began after an acute lower respiratory tract illness. This type of history has been labelled the \"infectious asthma\" \\\\(IA\\\\) syndrome, or as \"asthma associated with infection\" \\\\(AAWI\\\\) to distinguish infection-associated asthma initiation from the well known association of respiratory infections with asthma exacerbations. Reported clinical prevalences of IA for adults range from around 40% in a primary care practice to 70% in a specialty practice treating mainly severe asthma patients. Additional information on the clinical prevalence of IA in adult-onset asthma is unavailable because clinicians are not trained to elicit this type of history routinely, and recollection in child-onset asthma is challenging. A population-based incident case-control study in a geographically defined area of Finland reported that 35.8% of new-onset asthma cases had experienced acute bronchitis or pneumonia in the year preceding asthma onset, representing a significantly higher risk compared to randomly selected controls \\\\(Odds ratio 7.2, 95% confidence interval 5.2-10\\\\).'}\n",
      "\n",
      "{'type': 'Document', 'metadata': {'Title': 'Acute severe asthma', 'source': 'https://en.wikipedia.org/wiki/Acute_severe_asthma', 'Header2': 'Recent research'}, 'page_content': 'A recent study proposed that the interaction between host airway epithelial cells and respiratory viruses is another aspect of innate immunity that is also a critical determination of asthma. It was also proposed that a rationale for how antiviral performance at the epithelial cell level might be improved to prevent acute infectious illness and chronic inflammatory disease caused by respiratory viruses.  \\nAnother study aimed to show that experimental asthma after viral infection inmate depended on Type I IFN-driven up-regulation of the high-affinity receptor for IgE \\\\(FcεRI\\\\) on conventional dendritic cells \\\\(cDCs\\\\) in the lungs. The study found that a Novell PMN-cDc interaction in the lung is necessary for a viral infection to induce atopic disease.'}\n",
      "{'type': 'Document', 'metadata': {'Title': 'Anaphylaxis', 'source': 'https://en.wikipedia.org/wiki/Anaphylaxis', 'Header2': 'Management', 'Header3': 'Preparedness'}, 'page_content': \"People prone to anaphylaxis are advised to have an allergy action plan. Parents are advised to inform schools of their children's allergies and what to do in case of an anaphylactic emergency. The action plan usually includes use of epinephrine autoinjectors, the recommendation to wear a medical alert bracelet, and counseling on avoidance of triggers. Immunotherapy is available for certain triggers to prevent future episodes of anaphylaxis. A multi-year course of subcutaneous desensitization has been found effective against stinging insects, while oral desensitization is effective for many foods.\"}\n",
      "{'type': 'Document', 'metadata': {'Title': 'Asthma', 'source': 'https://en.wikipedia.org/wiki/Asthma', 'Header2': 'Diagnosis', 'Header3': 'Classification', 'Header4': 'Infectious asthma'}, 'page_content': 'Infectious asthma is an easily identified clinical presentation. When queried, asthma patients may report that their first asthma symptoms began after an acute lower respiratory tract illness. This type of history has been labelled the \"infectious asthma\" \\\\(IA\\\\) syndrome, or as \"asthma associated with infection\" \\\\(AAWI\\\\) to distinguish infection-associated asthma initiation from the well known association of respiratory infections with asthma exacerbations. Reported clinical prevalences of IA for adults range from around 40% in a primary care practice to 70% in a specialty practice treating mainly severe asthma patients. Additional information on the clinical prevalence of IA in adult-onset asthma is unavailable because clinicians are not trained to elicit this type of history routinely, and recollection in child-onset asthma is challenging. A population-based incident case-control study in a geographically defined area of Finland reported that 35.8% of new-onset asthma cases had experienced acute bronchitis or pneumonia in the year preceding asthma onset, representing a significantly higher risk compared to randomly selected controls \\\\(Odds ratio 7.2, 95% confidence interval 5.2-10\\\\).'}\n",
      "{'type': 'Document', 'metadata': {'Title': 'Asthma', 'source': 'https://en.wikipedia.org/wiki/Asthma', 'Header2': 'Diagnosis', 'Header3': 'Classification', 'Header4': 'Infectious asthma'}, 'page_content': 'Infectious asthma is an easily identified clinical presentation. When queried, asthma patients may report that their first asthma symptoms began after an acute lower respiratory tract illness. This type of history has been labelled the \"infectious asthma\" \\\\(IA\\\\) syndrome, or as \"asthma associated with infection\" \\\\(AAWI\\\\) to distinguish infection-associated asthma initiation from the well known association of respiratory infections with asthma exacerbations. Reported clinical prevalences of IA for adults range from around 40% in a primary care practice to 70% in a specialty practice treating mainly severe asthma patients. Additional information on the clinical prevalence of IA in adult-onset asthma is unavailable because clinicians are not trained to elicit this type of history routinely, and recollection in child-onset asthma is challenging. A population-based incident case-control study in a geographically defined area of Finland reported that 35.8% of new-onset asthma cases had experienced acute bronchitis or pneumonia in the year preceding asthma onset, representing a significantly higher risk compared to randomly selected controls \\\\(Odds ratio 7.2, 95% confidence interval 5.2-10\\\\).'}\n",
      "{'type': 'Document', 'metadata': {'Title': 'Acute severe asthma', 'source': 'https://en.wikipedia.org/wiki/Acute_severe_asthma', 'Header2': 'Cause'}, 'page_content': 'The cause for acute severe asthma attacks is still unknown and experts are also unsure of why it developed and why it does not respond to typical asthma treatments.  \\n* Not seeing a doctor regularly, therefore asthma is not under good control\\n* Coming in contact with asthma triggers\\n* Allergies or severe allergic reactions\\n* Not using the peak flow meter and not taking asthma medication as directed by a primary care physician \\\\(PCP\\\\) correctly\\n* Not following an asthma action plan correctly\\n* Respiratory infections\\n* Severe stress\\n* Cold weather\\n* Air pollution\\n* Exposure to chemicals and other irritants\\n* Smoking'}\n",
      "{'type': 'Document', 'metadata': {'Title': 'Asthma', 'source': 'https://en.wikipedia.org/wiki/Asthma', 'Header2': 'Introduction'}, 'page_content': \"Asthma is a long-term inflammatory disease of the airways of the lungs. It is characterized by variable and recurring symptoms, reversible airflow obstruction, and easily triggered bronchospasms. Symptoms include episodes of wheezing, coughing, chest tightness, and shortness of breath. These may occur a few times a day or a few times per week. Depending on the person, asthma symptoms may become worse at night or with exercise.  \\nAsthma is thought to be caused by a combination of genetic and environmental factors. Environmental factors include exposure to air pollution and allergens. Other potential triggers include medications such as aspirin and beta blockers. Diagnosis is usually based on the pattern of symptoms, response to therapy over time, and spirometry lung function testing. Asthma is classified according to the frequency of symptoms, forced expiratory volume in one second \\\\(FEV1\\\\), and peak expiratory flow rate. It may also be classified as atopic or non-atopic, where atopy refers to a predisposition toward developing a type 1 hypersensitivity reaction.  \\nThere is no known cure for asthma, but it can be controlled. Symptoms can be prevented by avoiding triggers, such as allergens and respiratory irritants, and suppressed with the use of inhaled corticosteroids. Long-acting beta agonists \\\\(LABA\\\\) or antileukotriene agents may be used in addition to inhaled corticosteroids if asthma symptoms remain uncontrolled. Treatment of rapidly worsening symptoms is usually with an inhaled short-acting beta2 agonist such as salbutamol and corticosteroids taken by mouth. In very severe cases, intravenous corticosteroids, magnesium sulfate, and hospitalization may be required.  \\nIn 2019 asthma affected approximately 262 million people and caused approximately 461,000 deaths. Most of the deaths occurred in the developing world. Asthma often begins in childhood, and the rates have increased significantly since the 1960s. Asthma was recognized as early as Ancient Egypt. The word asthma is from the Greek ἆσθμα, âsthma, which means 'panting'.\"}\n",
      "{'type': 'Document', 'metadata': {'Title': 'Asthma', 'source': 'https://en.wikipedia.org/wiki/Asthma', 'Header2': 'Causes'}, 'page_content': 'Asthma is caused by a combination of complex and incompletely understood environmental and genetic interactions. These influence both its severity and its responsiveness to treatment. It is believed that the recent increased rates of asthma are due to changing epigenetics \\\\(heritable factors other than those related to the DNA sequence\\\\) and a changing living environment. Asthma that starts before the age of 12 years old is more likely due to genetic influence, while onset after age 12 is more likely due to environmental influence.'}\n",
      "{'type': 'Document', 'metadata': {'Title': 'Acute severe asthma', 'source': 'https://en.wikipedia.org/wiki/Acute_severe_asthma', 'Header2': 'Introduction'}, 'page_content': 'Acute severe asthma, also known as status asthmaticus, is an acute exacerbation of asthma that does not respond to standard treatments of bronchodilators \\\\(inhalers\\\\) and corticosteroids. Asthma is caused by multiple genes, some having protective effect, with each gene having its own tendency to be influenced by the environment although a genetic link leading to acute severe asthma is still unknown. Symptoms include chest tightness, rapidly progressive dyspnea \\\\(shortness of breath\\\\), dry cough, use of accessory respiratory muscles, fast and/or labored breathing, and extreme wheezing. It is a life-threatening episode of airway obstruction and is considered a medical emergency. Complications include cardiac and/or respiratory arrest. The increasing prevalence of atopy and asthma remains unexplained but may be due to infection with respiratory viruses.'}\n",
      "{'type': 'Document', 'metadata': {'Title': 'Asthma', 'source': 'https://en.wikipedia.org/wiki/Asthma', 'Header2': 'Diagnosis', 'Header3': 'Classification', 'Header4': 'Asthma exacerbation'}, 'page_content': 'An acute asthma exacerbation is commonly referred to as an asthma attack. The classic symptoms are shortness of breath, wheezing, and chest tightness. The wheezing is most often when breathing out. While these are the primary symptoms of asthma, some people present primarily with coughing, and in severe cases, air motion may be significantly impaired such that no wheezing is heard. In children, chest pain is often present.  \\nSigns occurring during an asthma attack include the use of accessory muscles of respiration \\\\(sternocleidomastoid and scalene muscles of the neck\\\\), there may be a paradoxical pulse \\\\(a pulse that is weaker during inhalation and stronger during exhalation\\\\), and over-inflation of the chest. A blue color of the skin and nails may occur from lack of oxygen.  \\nIn a mild exacerbation the peak expiratory flow rate \\\\(PEFR\\\\) is ≥200 L/min, or ≥50% of the predicted best. Moderate is defined as between 80 and 200 L/min, or 25% and 50% of the predicted best, while severe is defined as ≤ 80 L/min, or ≤25% of the predicted best.  \\nAcute severe asthma, previously known as status asthmaticus, is an acute exacerbation of asthma that does not respond to standard treatments of bronchodilators and corticosteroids. Half of cases are due to infections with others caused by allergen, air pollution, or insufficient or inappropriate medication use.  \\nBrittle asthma is a kind of asthma distinguishable by recurrent, severe attacks. Type 1 brittle asthma is a disease with wide peak flow variability, despite intense medication. Type 2 brittle asthma is background well-controlled asthma with sudden severe exacerbations.'}\n",
      "{'type': 'Document', 'metadata': {'Title': 'Asthma', 'source': 'https://en.wikipedia.org/wiki/Asthma', 'Header2': 'Management', 'Header3': 'Lifestyle modification'}, 'page_content': 'Avoidance of triggers is a key component of improving control and preventing attacks. The most common triggers include allergens, smoke \\\\(from tobacco or other sources\\\\), air pollution, nonselective beta-blockers, and sulfite-containing foods. Cigarette smoking and second-hand smoke \\\\(passive smoke\\\\) may reduce the effectiveness of medications such as corticosteroids. Laws that limit smoking decrease the number of people hospitalized for asthma. Dust mite control measures, including air filtration, chemicals to kill mites, vacuuming, mattress covers and others methods had no effect on asthma symptoms. There is insufficient evidence to suggest that dehumidifiers are helpful for controlling asthma.  \\nOverall, exercise is beneficial in people with stable asthma. Yoga could provide small improvements in quality of life and symptoms in people with asthma. More research is necessary to determine how effective weight loss is on improving quality of life, the usage of health care services, and adverse effects for people of all ages with asthma.'}\n",
      "{'type': 'Document', 'metadata': {'Title': 'Asthma', 'source': 'https://en.wikipedia.org/wiki/Asthma', 'Header2': 'Management', 'Header3': 'Others'}, 'page_content': 'Inflammation in the lungs can be estimated by the level of exhaled nitric oxide. The use of exhaled nitric oxide levels \\\\(FeNO\\\\) to guide asthma medication dosing may have small benefits for preventing asthma attacks but the potential benefits are not strong enough for this approach to be universally recommended as a method to guide asthma therapy in adults or children.  \\nWhen asthma is unresponsive to usual medications, other options are available for both emergency management and prevention of flareups. Additional options include:  \\n* Humidified oxygen to alleviate hypoxia if saturations fall below 92%.\\n* Corticosteroid by mouth are recommended with five days of prednisone being the same 2 days of dexamethasone. One review recommended a seven-day course of steroids.\\n* Magnesium sulfate intravenous treatment increases bronchodilation when used in addition to other treatment in moderate severe acute asthma attacks. In adults intravenous treatment results in a reduction of hospital admissions. Low levels of evidence suggest that inhaled \\\\(nebulised\\\\) magnesium sulfate may have a small benefit for treating acute asthma in adults. Overall, high quality evidence do not indicate a large benefit for combining magnesium sulfate with standard inhaled treatments for adults with asthma.\\n* Heliox, a mixture of helium and oxygen, may also be considered in severe unresponsive cases.\\n* Intravenous salbutamol is not supported by available evidence and is thus used only in extreme cases.\\n* Methylxanthines \\\\(such as theophylline\\\\) were once widely used, but do not add significantly to the effects of inhaled beta-agonists. Their use in acute exacerbations is controversial.\\n* The dissociative anesthetic ketamine is theoretically useful if intubation and mechanical ventilation is needed in people who are approaching respiratory arrest; however, there is no evidence from clinical trials to support this. A 2012 Cochrane review found no significant benefit from the use of ketamine in severe acute asthma in children.\\n* For those with severe persistent asthma not controlled by inhaled corticosteroids and LABAs, bronchial thermoplasty may be an option. It involves the delivery of controlled thermal energy to the airway wall during a series of bronchoscopies. While it may increase exacerbation frequency in the first few months it appears to decrease the subsequent rate. Effects beyond one year are unknown.\\n* Monoclonal antibody injections such as mepolizumab, dupilumab, or omalizumab may be useful in those with poorly controlled atopic asthma. However, as of 2019 these medications are expensive and their use is therefore reserved for those with severe symptoms to achieve cost-effectiveness. Monoclonal antibodies targeting interleukin-5 \\\\(IL-5\\\\) or its receptor \\\\(IL-5R\\\\), including mepolizumab, reslizumab or benralizumab, in addition to standard care in severe asthma is effective in reducing the rate of asthma exacerbations. There is limited evidence for improved health-related quality of life and lung function.\\n* Evidence suggests that sublingual immunotherapy in those with both allergic rhinitis and asthma improve outcomes.\\n* It is unclear if non-invasive positive pressure ventilation in children is of use as it has not been sufficiently studied.'}\n",
      "{'type': 'Document', 'metadata': {'Title': 'Acute severe asthma', 'source': 'https://en.wikipedia.org/wiki/Acute_severe_asthma', 'Header2': 'Treatment'}, 'page_content': 'Interventions include intravenous \\\\(IV\\\\) medications \\\\(e.g. magnesium sulfate\\\\), aerosolized medications to dilate the airways \\\\(bronchodilation\\\\) \\\\(e.g., albuterol or ipratropium bromide/salbutamol\\\\), and positive-pressure therapy, including mechanical ventilation. Multiple therapies may be used simultaneously to rapidly reverse the effects of status asthmaticus and reduce permanent damage of the airways. Intravenous corticosteroids and methylxanthines are often given. If the person with a severe asthma exacerbation is on a mechanical ventilator, certain sedating medications such as ketamine or propofol, have bronchodilating properties. According to a new randomized control trial ketamine and aminophylline are also effective in children with acute asthma who responds poorly to standard therapy.'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator grade_docs> on run ed4b637b-bf1a-4258-bc03-a73dde6904d4: ValueError(\"Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '1', 'comment': 'grade for doc'}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 204, in _coerce_evaluation_result\n",
      "    return EvaluationResult(**{\"source_run_id\": source_run_id, **result})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/pydantic/v1/main.py\", line 341, in __init__\n",
      "    raise validation_error\n",
      "pydantic.v1.error_wrappers.ValidationError: 3 validation errors for EvaluationResult\n",
      "score\n",
      "  value is not a valid boolean (type=value_error.strictbool)\n",
      "score\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "score\n",
      "  value is not a valid float (type=type_error.float)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 284, in evaluate_run\n",
      "    return self._format_result(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 241, in _format_result\n",
      "    return self._coerce_evaluation_results(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 224, in _coerce_evaluation_results\n",
      "    return self._coerce_evaluation_result(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 206, in _coerce_evaluation_result\n",
      "    raise ValueError(\n",
      "ValueError: Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '1', 'comment': 'grade for doc'}\n",
      "Error running evaluator <DynamicRunEvaluator grade_docs> on run 578d9b3f-0087-4c99-9316-6abd52d9fac9: ValueError(\"Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '2', 'comment': 'grade for doc'}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 204, in _coerce_evaluation_result\n",
      "    return EvaluationResult(**{\"source_run_id\": source_run_id, **result})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/pydantic/v1/main.py\", line 341, in __init__\n",
      "    raise validation_error\n",
      "pydantic.v1.error_wrappers.ValidationError: 3 validation errors for EvaluationResult\n",
      "score\n",
      "  value is not a valid boolean (type=value_error.strictbool)\n",
      "score\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "score\n",
      "  value is not a valid float (type=type_error.float)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 284, in evaluate_run\n",
      "    return self._format_result(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 241, in _format_result\n",
      "    return self._coerce_evaluation_results(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 224, in _coerce_evaluation_results\n",
      "    return self._coerce_evaluation_result(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 206, in _coerce_evaluation_result\n",
      "    raise ValueError(\n",
      "ValueError: Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '2', 'comment': 'grade for doc'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Document', 'metadata': {'Title': 'Acute severe asthma', 'source': 'https://en.wikipedia.org/wiki/Acute_severe_asthma', 'Header2': 'Recent research'}, 'page_content': 'A recent study proposed that the interaction between host airway epithelial cells and respiratory viruses is another aspect of innate immunity that is also a critical determination of asthma. It was also proposed that a rationale for how antiviral performance at the epithelial cell level might be improved to prevent acute infectious illness and chronic inflammatory disease caused by respiratory viruses.  \\nAnother study aimed to show that experimental asthma after viral infection inmate depended on Type I IFN-driven up-regulation of the high-affinity receptor for IgE \\\\(FcεRI\\\\) on conventional dendritic cells \\\\(cDCs\\\\) in the lungs. The study found that a Novell PMN-cDc interaction in the lung is necessary for a viral infection to induce atopic disease.'}\n",
      "{'type': 'Document', 'metadata': {'Title': 'Asthma', 'source': 'https://en.wikipedia.org/wiki/Asthma', 'Header2': 'Management', 'Header3': 'Lifestyle modification'}, 'page_content': 'Avoidance of triggers is a key component of improving control and preventing attacks. The most common triggers include allergens, smoke \\\\(from tobacco or other sources\\\\), air pollution, nonselective beta-blockers, and sulfite-containing foods. Cigarette smoking and second-hand smoke \\\\(passive smoke\\\\) may reduce the effectiveness of medications such as corticosteroids. Laws that limit smoking decrease the number of people hospitalized for asthma. Dust mite control measures, including air filtration, chemicals to kill mites, vacuuming, mattress covers and others methods had no effect on asthma symptoms. There is insufficient evidence to suggest that dehumidifiers are helpful for controlling asthma.  \\nOverall, exercise is beneficial in people with stable asthma. Yoga could provide small improvements in quality of life and symptoms in people with asthma. More research is necessary to determine how effective weight loss is on improving quality of life, the usage of health care services, and adverse effects for people of all ages with asthma.'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator grade_docs> on run c817e9ad-4dcb-407e-8f89-baefd01c481b: ValueError(\"Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '1', 'comment': 'grade for doc'}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 204, in _coerce_evaluation_result\n",
      "    return EvaluationResult(**{\"source_run_id\": source_run_id, **result})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/pydantic/v1/main.py\", line 341, in __init__\n",
      "    raise validation_error\n",
      "pydantic.v1.error_wrappers.ValidationError: 3 validation errors for EvaluationResult\n",
      "score\n",
      "  value is not a valid boolean (type=value_error.strictbool)\n",
      "score\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "score\n",
      "  value is not a valid float (type=type_error.float)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 284, in evaluate_run\n",
      "    return self._format_result(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 241, in _format_result\n",
      "    return self._coerce_evaluation_results(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 224, in _coerce_evaluation_results\n",
      "    return self._coerce_evaluation_result(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 206, in _coerce_evaluation_result\n",
      "    raise ValueError(\n",
      "ValueError: Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '1', 'comment': 'grade for doc'}\n",
      "Error running evaluator <DynamicRunEvaluator grade_docs> on run 052d5866-41d6-4fca-ae51-7426b5acac32: ValueError(\"Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '1', 'comment': 'grade for doc'}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 204, in _coerce_evaluation_result\n",
      "    return EvaluationResult(**{\"source_run_id\": source_run_id, **result})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/pydantic/v1/main.py\", line 341, in __init__\n",
      "    raise validation_error\n",
      "pydantic.v1.error_wrappers.ValidationError: 3 validation errors for EvaluationResult\n",
      "score\n",
      "  value is not a valid boolean (type=value_error.strictbool)\n",
      "score\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "score\n",
      "  value is not a valid float (type=type_error.float)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 284, in evaluate_run\n",
      "    return self._format_result(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 241, in _format_result\n",
      "    return self._coerce_evaluation_results(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 224, in _coerce_evaluation_results\n",
      "    return self._coerce_evaluation_result(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 206, in _coerce_evaluation_result\n",
      "    raise ValueError(\n",
      "ValueError: Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '1', 'comment': 'grade for doc'}\n",
      "Error running evaluator <DynamicRunEvaluator grade_docs> on run 5f0786e8-5eac-4418-a41c-e1220092a898: ValueError(\"Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '2', 'comment': 'grade for doc'}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 204, in _coerce_evaluation_result\n",
      "    return EvaluationResult(**{\"source_run_id\": source_run_id, **result})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/pydantic/v1/main.py\", line 341, in __init__\n",
      "    raise validation_error\n",
      "pydantic.v1.error_wrappers.ValidationError: 3 validation errors for EvaluationResult\n",
      "score\n",
      "  value is not a valid boolean (type=value_error.strictbool)\n",
      "score\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "score\n",
      "  value is not a valid float (type=type_error.float)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 284, in evaluate_run\n",
      "    return self._format_result(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 241, in _format_result\n",
      "    return self._coerce_evaluation_results(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 224, in _coerce_evaluation_results\n",
      "    return self._coerce_evaluation_result(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 206, in _coerce_evaluation_result\n",
      "    raise ValueError(\n",
      "ValueError: Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '2', 'comment': 'grade for doc'}\n",
      "Error running evaluator <DynamicRunEvaluator grade_docs> on run c742e0a5-b325-421f-9853-e26821d9ce76: ValueError(\"Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '1', 'comment': 'grade for doc'}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 204, in _coerce_evaluation_result\n",
      "    return EvaluationResult(**{\"source_run_id\": source_run_id, **result})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/pydantic/v1/main.py\", line 341, in __init__\n",
      "    raise validation_error\n",
      "pydantic.v1.error_wrappers.ValidationError: 3 validation errors for EvaluationResult\n",
      "score\n",
      "  value is not a valid boolean (type=value_error.strictbool)\n",
      "score\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "score\n",
      "  value is not a valid float (type=type_error.float)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 284, in evaluate_run\n",
      "    return self._format_result(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 241, in _format_result\n",
      "    return self._coerce_evaluation_results(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 224, in _coerce_evaluation_results\n",
      "    return self._coerce_evaluation_result(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 206, in _coerce_evaluation_result\n",
      "    raise ValueError(\n",
      "ValueError: Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '1', 'comment': 'grade for doc'}\n",
      "Error running evaluator <DynamicRunEvaluator grade_docs> on run 4c851bf2-5a99-4833-84bb-2b2211b4bfde: ValueError(\"Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '2', 'comment': 'grade for doc'}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 204, in _coerce_evaluation_result\n",
      "    return EvaluationResult(**{\"source_run_id\": source_run_id, **result})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/pydantic/v1/main.py\", line 341, in __init__\n",
      "    raise validation_error\n",
      "pydantic.v1.error_wrappers.ValidationError: 3 validation errors for EvaluationResult\n",
      "score\n",
      "  value is not a valid boolean (type=value_error.strictbool)\n",
      "score\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "score\n",
      "  value is not a valid float (type=type_error.float)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 284, in evaluate_run\n",
      "    return self._format_result(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 241, in _format_result\n",
      "    return self._coerce_evaluation_results(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 224, in _coerce_evaluation_results\n",
      "    return self._coerce_evaluation_result(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 206, in _coerce_evaluation_result\n",
      "    raise ValueError(\n",
      "ValueError: Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '2', 'comment': 'grade for doc'}\n",
      "Error running evaluator <DynamicRunEvaluator grade_docs> on run a4240e85-b6fd-4ac5-a778-be7a1cb562fd: ValueError(\"Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '1', 'comment': 'grade for doc'}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 204, in _coerce_evaluation_result\n",
      "    return EvaluationResult(**{\"source_run_id\": source_run_id, **result})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/pydantic/v1/main.py\", line 341, in __init__\n",
      "    raise validation_error\n",
      "pydantic.v1.error_wrappers.ValidationError: 3 validation errors for EvaluationResult\n",
      "score\n",
      "  value is not a valid boolean (type=value_error.strictbool)\n",
      "score\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "score\n",
      "  value is not a valid float (type=type_error.float)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 284, in evaluate_run\n",
      "    return self._format_result(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 241, in _format_result\n",
      "    return self._coerce_evaluation_results(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 224, in _coerce_evaluation_results\n",
      "    return self._coerce_evaluation_result(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 206, in _coerce_evaluation_result\n",
      "    raise ValueError(\n",
      "ValueError: Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '1', 'comment': 'grade for doc'}\n",
      "Error running evaluator <DynamicRunEvaluator grade_docs> on run 647a5365-4627-4d02-b9b4-95f1ae4d6f4d: ValueError(\"Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '2', 'comment': 'grade for doc'}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 204, in _coerce_evaluation_result\n",
      "    return EvaluationResult(**{\"source_run_id\": source_run_id, **result})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/pydantic/v1/main.py\", line 341, in __init__\n",
      "    raise validation_error\n",
      "pydantic.v1.error_wrappers.ValidationError: 3 validation errors for EvaluationResult\n",
      "score\n",
      "  value is not a valid boolean (type=value_error.strictbool)\n",
      "score\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "score\n",
      "  value is not a valid float (type=type_error.float)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 284, in evaluate_run\n",
      "    return self._format_result(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 241, in _format_result\n",
      "    return self._coerce_evaluation_results(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 224, in _coerce_evaluation_results\n",
      "    return self._coerce_evaluation_result(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 206, in _coerce_evaluation_result\n",
      "    raise ValueError(\n",
      "ValueError: Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '2', 'comment': 'grade for doc'}\n",
      "Error running evaluator <DynamicRunEvaluator grade_docs> on run 17be0217-d703-439d-b52a-25339c76a28f: ValueError(\"Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '1', 'comment': 'grade for doc'}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 204, in _coerce_evaluation_result\n",
      "    return EvaluationResult(**{\"source_run_id\": source_run_id, **result})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/pydantic/v1/main.py\", line 341, in __init__\n",
      "    raise validation_error\n",
      "pydantic.v1.error_wrappers.ValidationError: 3 validation errors for EvaluationResult\n",
      "score\n",
      "  value is not a valid boolean (type=value_error.strictbool)\n",
      "score\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "score\n",
      "  value is not a valid float (type=type_error.float)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 284, in evaluate_run\n",
      "    return self._format_result(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 241, in _format_result\n",
      "    return self._coerce_evaluation_results(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 224, in _coerce_evaluation_results\n",
      "    return self._coerce_evaluation_result(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 206, in _coerce_evaluation_result\n",
      "    raise ValueError(\n",
      "ValueError: Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '1', 'comment': 'grade for doc'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Document', 'metadata': {'Title': 'Asthma-COPD overlap', 'source': 'https://en.wikipedia.org/wiki/Asthma-COPD_overlap', 'Header2': 'Treatment'}, 'page_content': 'Treatment of ACO is based on expert opinion as there are no universally accepted clinical guidelines. Treatment is usually based on whether clinical features of asthma or COPD predominate. Inhaled corticosteroids are the primary treatment in those with ACOS. Inhaled corticosteroids \\\\(ICS\\\\) should be continued in those with asthma who develop decreased airway responsiveness to bronchodilators consistent with ACO. Therapy can be escalated to include a long acting beta-agonist \\\\(LABA\\\\) and inhaled steroid combination \\\\(ICS-LABA\\\\) or by adding on a long-acting anti-muscarinic inhaler \\\\(LAMA\\\\), known as triple therapy, in those with more severe or resistant disease.  \\nMonoclonal antibodies targeting type 2 inflammation \\\\(which is predominant in asthma\\\\) have been used to treat severe asthma, and may also be used in severe cases of ACO. These monoclonal antibodies include omalizumab \\\\(an Anti-IgE antibody\\\\), mepolizumab \\\\(an anti-IL-5 antibody\\\\) and benralizumab \\\\(an anti-IL-5 receptor α antibody\\\\). People with ACOS and eosinophilia have a better response to ICS; with fewer exacerbations and hospitalizations seen in ACOS treated with long term ICS. Systemic corticosteroids \\\\(intravenous or oral steroids\\\\) may be used during exacerbations of ACOS.'}\n",
      "{'type': 'Document', 'metadata': {'Title': 'Childhood chronic illness', 'source': 'https://en.wikipedia.org/wiki/Childhood_chronic_illness', 'Header2': 'Common Childhood Chronic Diseases', 'Header3': 'Asthma'}, 'page_content': 'Asthma is a common chronic disease in children that impacts their ability to breathe. The disease is characterized by inflammation of the airways and patients will commonly present with coughing, shortness of breath and wheezing. Asthma in children is typically triggered by environmental antigens, allergies, viral respiratory infections, fumes, obesity, and emotional factors including stress.'}\n",
      "{'type': 'Document', 'metadata': {'Title': 'Acute severe asthma', 'source': 'https://en.wikipedia.org/wiki/Acute_severe_asthma', 'Header2': 'Recent research'}, 'page_content': 'A recent study proposed that the interaction between host airway epithelial cells and respiratory viruses is another aspect of innate immunity that is also a critical determination of asthma. It was also proposed that a rationale for how antiviral performance at the epithelial cell level might be improved to prevent acute infectious illness and chronic inflammatory disease caused by respiratory viruses.  \\nAnother study aimed to show that experimental asthma after viral infection inmate depended on Type I IFN-driven up-regulation of the high-affinity receptor for IgE \\\\(FcεRI\\\\) on conventional dendritic cells \\\\(cDCs\\\\) in the lungs. The study found that a Novell PMN-cDc interaction in the lung is necessary for a viral infection to induce atopic disease.'}\n",
      "{'type': 'Document', 'metadata': {'Title': 'Asthma', 'source': 'https://en.wikipedia.org/wiki/Asthma', 'Header2': 'Diagnosis', 'Header3': 'Classification', 'Header4': 'Infectious asthma'}, 'page_content': 'Infectious asthma is an easily identified clinical presentation. When queried, asthma patients may report that their first asthma symptoms began after an acute lower respiratory tract illness. This type of history has been labelled the \"infectious asthma\" \\\\(IA\\\\) syndrome, or as \"asthma associated with infection\" \\\\(AAWI\\\\) to distinguish infection-associated asthma initiation from the well known association of respiratory infections with asthma exacerbations. Reported clinical prevalences of IA for adults range from around 40% in a primary care practice to 70% in a specialty practice treating mainly severe asthma patients. Additional information on the clinical prevalence of IA in adult-onset asthma is unavailable because clinicians are not trained to elicit this type of history routinely, and recollection in child-onset asthma is challenging. A population-based incident case-control study in a geographically defined area of Finland reported that 35.8% of new-onset asthma cases had experienced acute bronchitis or pneumonia in the year preceding asthma onset, representing a significantly higher risk compared to randomly selected controls \\\\(Odds ratio 7.2, 95% confidence interval 5.2-10\\\\).'}\n",
      "{'type': 'Document', 'metadata': {'Title': 'Asthma', 'source': 'https://en.wikipedia.org/wiki/Asthma', 'Header2': 'Introduction'}, 'page_content': \"Asthma is a long-term inflammatory disease of the airways of the lungs. It is characterized by variable and recurring symptoms, reversible airflow obstruction, and easily triggered bronchospasms. Symptoms include episodes of wheezing, coughing, chest tightness, and shortness of breath. These may occur a few times a day or a few times per week. Depending on the person, asthma symptoms may become worse at night or with exercise.  \\nAsthma is thought to be caused by a combination of genetic and environmental factors. Environmental factors include exposure to air pollution and allergens. Other potential triggers include medications such as aspirin and beta blockers. Diagnosis is usually based on the pattern of symptoms, response to therapy over time, and spirometry lung function testing. Asthma is classified according to the frequency of symptoms, forced expiratory volume in one second \\\\(FEV1\\\\), and peak expiratory flow rate. It may also be classified as atopic or non-atopic, where atopy refers to a predisposition toward developing a type 1 hypersensitivity reaction.  \\nThere is no known cure for asthma, but it can be controlled. Symptoms can be prevented by avoiding triggers, such as allergens and respiratory irritants, and suppressed with the use of inhaled corticosteroids. Long-acting beta agonists \\\\(LABA\\\\) or antileukotriene agents may be used in addition to inhaled corticosteroids if asthma symptoms remain uncontrolled. Treatment of rapidly worsening symptoms is usually with an inhaled short-acting beta2 agonist such as salbutamol and corticosteroids taken by mouth. In very severe cases, intravenous corticosteroids, magnesium sulfate, and hospitalization may be required.  \\nIn 2019 asthma affected approximately 262 million people and caused approximately 461,000 deaths. Most of the deaths occurred in the developing world. Asthma often begins in childhood, and the rates have increased significantly since the 1960s. Asthma was recognized as early as Ancient Egypt. The word asthma is from the Greek ἆσθμα, âsthma, which means 'panting'.\"}\n",
      "{'type': 'Document', 'metadata': {'Title': 'Asthma', 'source': 'https://en.wikipedia.org/wiki/Asthma', 'Header2': 'Diagnosis', 'Header3': 'Classification', 'Header4': 'Infectious asthma'}, 'page_content': 'Infectious asthma is an easily identified clinical presentation. When queried, asthma patients may report that their first asthma symptoms began after an acute lower respiratory tract illness. This type of history has been labelled the \"infectious asthma\" \\\\(IA\\\\) syndrome, or as \"asthma associated with infection\" \\\\(AAWI\\\\) to distinguish infection-associated asthma initiation from the well known association of respiratory infections with asthma exacerbations. Reported clinical prevalences of IA for adults range from around 40% in a primary care practice to 70% in a specialty practice treating mainly severe asthma patients. Additional information on the clinical prevalence of IA in adult-onset asthma is unavailable because clinicians are not trained to elicit this type of history routinely, and recollection in child-onset asthma is challenging. A population-based incident case-control study in a geographically defined area of Finland reported that 35.8% of new-onset asthma cases had experienced acute bronchitis or pneumonia in the year preceding asthma onset, representing a significantly higher risk compared to randomly selected controls \\\\(Odds ratio 7.2, 95% confidence interval 5.2-10\\\\).'}\n",
      "{'type': 'Document', 'metadata': {'Title': 'Childhood chronic illness', 'source': 'https://en.wikipedia.org/wiki/Childhood_chronic_illness', 'Header2': 'Common Childhood Chronic Diseases', 'Header3': 'Asthma'}, 'page_content': 'Asthma is a common chronic disease in children that impacts their ability to breathe. The disease is characterized by inflammation of the airways and patients will commonly present with coughing, shortness of breath and wheezing. Asthma in children is typically triggered by environmental antigens, allergies, viral respiratory infections, fumes, obesity, and emotional factors including stress.'}\n",
      "{'type': 'Document', 'metadata': {'Title': 'Asthma', 'source': 'https://en.wikipedia.org/wiki/Asthma', 'Header2': 'Introduction'}, 'page_content': \"Asthma is a long-term inflammatory disease of the airways of the lungs. It is characterized by variable and recurring symptoms, reversible airflow obstruction, and easily triggered bronchospasms. Symptoms include episodes of wheezing, coughing, chest tightness, and shortness of breath. These may occur a few times a day or a few times per week. Depending on the person, asthma symptoms may become worse at night or with exercise.  \\nAsthma is thought to be caused by a combination of genetic and environmental factors. Environmental factors include exposure to air pollution and allergens. Other potential triggers include medications such as aspirin and beta blockers. Diagnosis is usually based on the pattern of symptoms, response to therapy over time, and spirometry lung function testing. Asthma is classified according to the frequency of symptoms, forced expiratory volume in one second \\\\(FEV1\\\\), and peak expiratory flow rate. It may also be classified as atopic or non-atopic, where atopy refers to a predisposition toward developing a type 1 hypersensitivity reaction.  \\nThere is no known cure for asthma, but it can be controlled. Symptoms can be prevented by avoiding triggers, such as allergens and respiratory irritants, and suppressed with the use of inhaled corticosteroids. Long-acting beta agonists \\\\(LABA\\\\) or antileukotriene agents may be used in addition to inhaled corticosteroids if asthma symptoms remain uncontrolled. Treatment of rapidly worsening symptoms is usually with an inhaled short-acting beta2 agonist such as salbutamol and corticosteroids taken by mouth. In very severe cases, intravenous corticosteroids, magnesium sulfate, and hospitalization may be required.  \\nIn 2019 asthma affected approximately 262 million people and caused approximately 461,000 deaths. Most of the deaths occurred in the developing world. Asthma often begins in childhood, and the rates have increased significantly since the 1960s. Asthma was recognized as early as Ancient Egypt. The word asthma is from the Greek ἆσθμα, âsthma, which means 'panting'.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator grade_docs> on run 49c309e8-1563-4db8-b514-1a2775634ea1: ValueError(\"Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '2', 'comment': 'grade for doc'}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 204, in _coerce_evaluation_result\n",
      "    return EvaluationResult(**{\"source_run_id\": source_run_id, **result})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/pydantic/v1/main.py\", line 341, in __init__\n",
      "    raise validation_error\n",
      "pydantic.v1.error_wrappers.ValidationError: 3 validation errors for EvaluationResult\n",
      "score\n",
      "  value is not a valid boolean (type=value_error.strictbool)\n",
      "score\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "score\n",
      "  value is not a valid float (type=type_error.float)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 284, in evaluate_run\n",
      "    return self._format_result(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 241, in _format_result\n",
      "    return self._coerce_evaluation_results(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 224, in _coerce_evaluation_results\n",
      "    return self._coerce_evaluation_result(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 206, in _coerce_evaluation_result\n",
      "    raise ValueError(\n",
      "ValueError: Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '2', 'comment': 'grade for doc'}\n",
      "Error running evaluator <DynamicRunEvaluator grade_docs> on run d8b7f1ad-6081-4970-ac09-ea40293e68ef: ValueError(\"Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '1', 'comment': 'grade for doc'}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 204, in _coerce_evaluation_result\n",
      "    return EvaluationResult(**{\"source_run_id\": source_run_id, **result})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/pydantic/v1/main.py\", line 341, in __init__\n",
      "    raise validation_error\n",
      "pydantic.v1.error_wrappers.ValidationError: 3 validation errors for EvaluationResult\n",
      "score\n",
      "  value is not a valid boolean (type=value_error.strictbool)\n",
      "score\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "score\n",
      "  value is not a valid float (type=type_error.float)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 284, in evaluate_run\n",
      "    return self._format_result(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 241, in _format_result\n",
      "    return self._coerce_evaluation_results(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 224, in _coerce_evaluation_results\n",
      "    return self._coerce_evaluation_result(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 206, in _coerce_evaluation_result\n",
      "    raise ValueError(\n",
      "ValueError: Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '1', 'comment': 'grade for doc'}\n",
      "Error running evaluator <DynamicRunEvaluator grade_docs> on run 1920cf93-fdc7-467c-a8a0-f9f1963b715a: ValueError(\"Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '1', 'comment': 'grade for doc'}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 204, in _coerce_evaluation_result\n",
      "    return EvaluationResult(**{\"source_run_id\": source_run_id, **result})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/pydantic/v1/main.py\", line 341, in __init__\n",
      "    raise validation_error\n",
      "pydantic.v1.error_wrappers.ValidationError: 3 validation errors for EvaluationResult\n",
      "score\n",
      "  value is not a valid boolean (type=value_error.strictbool)\n",
      "score\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "score\n",
      "  value is not a valid float (type=type_error.float)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 284, in evaluate_run\n",
      "    return self._format_result(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 241, in _format_result\n",
      "    return self._coerce_evaluation_results(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 224, in _coerce_evaluation_results\n",
      "    return self._coerce_evaluation_result(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 206, in _coerce_evaluation_result\n",
      "    raise ValueError(\n",
      "ValueError: Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '1', 'comment': 'grade for doc'}\n",
      "Error running evaluator <DynamicRunEvaluator grade_docs> on run e30f93f1-ce36-4a03-b3fe-c2159e2adfb2: ValueError(\"Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '1', 'comment': 'grade for doc'}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 204, in _coerce_evaluation_result\n",
      "    return EvaluationResult(**{\"source_run_id\": source_run_id, **result})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/pydantic/v1/main.py\", line 341, in __init__\n",
      "    raise validation_error\n",
      "pydantic.v1.error_wrappers.ValidationError: 3 validation errors for EvaluationResult\n",
      "score\n",
      "  value is not a valid boolean (type=value_error.strictbool)\n",
      "score\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "score\n",
      "  value is not a valid float (type=type_error.float)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 284, in evaluate_run\n",
      "    return self._format_result(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 241, in _format_result\n",
      "    return self._coerce_evaluation_results(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 224, in _coerce_evaluation_results\n",
      "    return self._coerce_evaluation_result(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 206, in _coerce_evaluation_result\n",
      "    raise ValueError(\n",
      "ValueError: Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '1', 'comment': 'grade for doc'}\n",
      "Error running evaluator <DynamicRunEvaluator grade_docs> on run 144aab7e-630d-45c8-b72f-6663575a1f2d: ValueError(\"Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '1', 'comment': 'grade for doc'}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 204, in _coerce_evaluation_result\n",
      "    return EvaluationResult(**{\"source_run_id\": source_run_id, **result})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/pydantic/v1/main.py\", line 341, in __init__\n",
      "    raise validation_error\n",
      "pydantic.v1.error_wrappers.ValidationError: 3 validation errors for EvaluationResult\n",
      "score\n",
      "  value is not a valid boolean (type=value_error.strictbool)\n",
      "score\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "score\n",
      "  value is not a valid float (type=type_error.float)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 284, in evaluate_run\n",
      "    return self._format_result(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 241, in _format_result\n",
      "    return self._coerce_evaluation_results(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 224, in _coerce_evaluation_results\n",
      "    return self._coerce_evaluation_result(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 206, in _coerce_evaluation_result\n",
      "    raise ValueError(\n",
      "ValueError: Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '1', 'comment': 'grade for doc'}\n",
      "Error running evaluator <DynamicRunEvaluator grade_docs> on run 6e63ee5c-b03b-42bf-804e-751d5295f8d5: ValueError(\"Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '1', 'comment': 'grade for doc'}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 204, in _coerce_evaluation_result\n",
      "    return EvaluationResult(**{\"source_run_id\": source_run_id, **result})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/pydantic/v1/main.py\", line 341, in __init__\n",
      "    raise validation_error\n",
      "pydantic.v1.error_wrappers.ValidationError: 3 validation errors for EvaluationResult\n",
      "score\n",
      "  value is not a valid boolean (type=value_error.strictbool)\n",
      "score\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "score\n",
      "  value is not a valid float (type=type_error.float)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 284, in evaluate_run\n",
      "    return self._format_result(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 241, in _format_result\n",
      "    return self._coerce_evaluation_results(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 224, in _coerce_evaluation_results\n",
      "    return self._coerce_evaluation_result(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 206, in _coerce_evaluation_result\n",
      "    raise ValueError(\n",
      "ValueError: Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '1', 'comment': 'grade for doc'}\n",
      "Error running evaluator <DynamicRunEvaluator grade_docs> on run ee101e4b-757f-48ec-a78f-24d2d050758b: ValueError(\"Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '2', 'comment': 'grade for doc'}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 204, in _coerce_evaluation_result\n",
      "    return EvaluationResult(**{\"source_run_id\": source_run_id, **result})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/pydantic/v1/main.py\", line 341, in __init__\n",
      "    raise validation_error\n",
      "pydantic.v1.error_wrappers.ValidationError: 3 validation errors for EvaluationResult\n",
      "score\n",
      "  value is not a valid boolean (type=value_error.strictbool)\n",
      "score\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "score\n",
      "  value is not a valid float (type=type_error.float)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 284, in evaluate_run\n",
      "    return self._format_result(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 241, in _format_result\n",
      "    return self._coerce_evaluation_results(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 224, in _coerce_evaluation_results\n",
      "    return self._coerce_evaluation_result(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 206, in _coerce_evaluation_result\n",
      "    raise ValueError(\n",
      "ValueError: Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '2', 'comment': 'grade for doc'}\n",
      "Error running evaluator <DynamicRunEvaluator grade_docs> on run 09e76de3-d088-451c-8d90-21f83a8105d9: ValueError(\"Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '1', 'comment': 'grade for doc'}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 204, in _coerce_evaluation_result\n",
      "    return EvaluationResult(**{\"source_run_id\": source_run_id, **result})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/pydantic/v1/main.py\", line 341, in __init__\n",
      "    raise validation_error\n",
      "pydantic.v1.error_wrappers.ValidationError: 3 validation errors for EvaluationResult\n",
      "score\n",
      "  value is not a valid boolean (type=value_error.strictbool)\n",
      "score\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "score\n",
      "  value is not a valid float (type=type_error.float)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 284, in evaluate_run\n",
      "    return self._format_result(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 241, in _format_result\n",
      "    return self._coerce_evaluation_results(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 224, in _coerce_evaluation_results\n",
      "    return self._coerce_evaluation_result(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 206, in _coerce_evaluation_result\n",
      "    raise ValueError(\n",
      "ValueError: Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '1', 'comment': 'grade for doc'}\n",
      "Error running evaluator <DynamicRunEvaluator grade_docs> on run 91ae0e93-9825-4add-97a7-8f2c9e7f033f: ValueError(\"Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '1', 'comment': 'grade for doc'}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 204, in _coerce_evaluation_result\n",
      "    return EvaluationResult(**{\"source_run_id\": source_run_id, **result})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/pydantic/v1/main.py\", line 341, in __init__\n",
      "    raise validation_error\n",
      "pydantic.v1.error_wrappers.ValidationError: 3 validation errors for EvaluationResult\n",
      "score\n",
      "  value is not a valid boolean (type=value_error.strictbool)\n",
      "score\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "score\n",
      "  value is not a valid float (type=type_error.float)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 284, in evaluate_run\n",
      "    return self._format_result(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 241, in _format_result\n",
      "    return self._coerce_evaluation_results(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 224, in _coerce_evaluation_results\n",
      "    return self._coerce_evaluation_result(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 206, in _coerce_evaluation_result\n",
      "    raise ValueError(\n",
      "ValueError: Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '1', 'comment': 'grade for doc'}\n",
      "Error running evaluator <DynamicRunEvaluator grade_docs> on run fd147772-15b1-4cb7-b636-5e0cae85f30a: ValueError(\"Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '2', 'comment': 'grade for doc'}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 204, in _coerce_evaluation_result\n",
      "    return EvaluationResult(**{\"source_run_id\": source_run_id, **result})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/pydantic/v1/main.py\", line 341, in __init__\n",
      "    raise validation_error\n",
      "pydantic.v1.error_wrappers.ValidationError: 3 validation errors for EvaluationResult\n",
      "score\n",
      "  value is not a valid boolean (type=value_error.strictbool)\n",
      "score\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "score\n",
      "  value is not a valid float (type=type_error.float)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 284, in evaluate_run\n",
      "    return self._format_result(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 241, in _format_result\n",
      "    return self._coerce_evaluation_results(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 224, in _coerce_evaluation_results\n",
      "    return self._coerce_evaluation_result(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 206, in _coerce_evaluation_result\n",
      "    raise ValueError(\n",
      "ValueError: Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '2', 'comment': 'grade for doc'}\n",
      "Error running evaluator <DynamicRunEvaluator grade_docs> on run 29bfb9f0-461d-4943-bc7e-93639dbdac9f: ValueError(\"Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '2', 'comment': 'grade for doc'}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 204, in _coerce_evaluation_result\n",
      "    return EvaluationResult(**{\"source_run_id\": source_run_id, **result})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/pydantic/v1/main.py\", line 341, in __init__\n",
      "    raise validation_error\n",
      "pydantic.v1.error_wrappers.ValidationError: 3 validation errors for EvaluationResult\n",
      "score\n",
      "  value is not a valid boolean (type=value_error.strictbool)\n",
      "score\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "score\n",
      "  value is not a valid float (type=type_error.float)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 284, in evaluate_run\n",
      "    return self._format_result(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 241, in _format_result\n",
      "    return self._coerce_evaluation_results(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 224, in _coerce_evaluation_results\n",
      "    return self._coerce_evaluation_result(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 206, in _coerce_evaluation_result\n",
      "    raise ValueError(\n",
      "ValueError: Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '2', 'comment': 'grade for doc'}\n",
      "Error running evaluator <DynamicRunEvaluator grade_docs> on run be11471f-caa8-4e2c-9201-cbfea6c69069: ValueError(\"Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '1', 'comment': 'grade for doc'}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 204, in _coerce_evaluation_result\n",
      "    return EvaluationResult(**{\"source_run_id\": source_run_id, **result})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/pydantic/v1/main.py\", line 341, in __init__\n",
      "    raise validation_error\n",
      "pydantic.v1.error_wrappers.ValidationError: 3 validation errors for EvaluationResult\n",
      "score\n",
      "  value is not a valid boolean (type=value_error.strictbool)\n",
      "score\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "score\n",
      "  value is not a valid float (type=type_error.float)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 284, in evaluate_run\n",
      "    return self._format_result(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 241, in _format_result\n",
      "    return self._coerce_evaluation_results(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 224, in _coerce_evaluation_results\n",
      "    return self._coerce_evaluation_result(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 206, in _coerce_evaluation_result\n",
      "    raise ValueError(\n",
      "ValueError: Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '1', 'comment': 'grade for doc'}\n",
      "Error running evaluator <DynamicRunEvaluator grade_docs> on run a4fa83dd-3dfb-440a-9dca-0c05f6c41171: ValueError(\"Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '2', 'comment': 'grade for doc'}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 204, in _coerce_evaluation_result\n",
      "    return EvaluationResult(**{\"source_run_id\": source_run_id, **result})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/pydantic/v1/main.py\", line 341, in __init__\n",
      "    raise validation_error\n",
      "pydantic.v1.error_wrappers.ValidationError: 3 validation errors for EvaluationResult\n",
      "score\n",
      "  value is not a valid boolean (type=value_error.strictbool)\n",
      "score\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "score\n",
      "  value is not a valid float (type=type_error.float)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 284, in evaluate_run\n",
      "    return self._format_result(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 241, in _format_result\n",
      "    return self._coerce_evaluation_results(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 224, in _coerce_evaluation_results\n",
      "    return self._coerce_evaluation_result(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 206, in _coerce_evaluation_result\n",
      "    raise ValueError(\n",
      "ValueError: Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '2', 'comment': 'grade for doc'}\n",
      "Error running evaluator <DynamicRunEvaluator grade_docs> on run d8360a1c-eb50-46c1-aa90-0f7f34850bcb: ValueError(\"Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '1', 'comment': 'grade for doc'}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 204, in _coerce_evaluation_result\n",
      "    return EvaluationResult(**{\"source_run_id\": source_run_id, **result})\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/pydantic/v1/main.py\", line 341, in __init__\n",
      "    raise validation_error\n",
      "pydantic.v1.error_wrappers.ValidationError: 3 validation errors for EvaluationResult\n",
      "score\n",
      "  value is not a valid boolean (type=value_error.strictbool)\n",
      "score\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "score\n",
      "  value is not a valid float (type=type_error.float)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1216, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 284, in evaluate_run\n",
      "    return self._format_result(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 241, in _format_result\n",
      "    return self._coerce_evaluation_results(result, source_run_id)\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 224, in _coerce_evaluation_results\n",
      "    return self._coerce_evaluation_result(\n",
      "  File \"/Users/a_wei/miniconda3/envs/llm/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 206, in _coerce_evaluation_result\n",
      "    raise ValueError(\n",
      "ValueError: Expected an EvaluationResult object, or dict with a metric 'key' and optional 'score'; got {'key': 'grade', 'score': '1', 'comment': 'grade for doc'}\n"
     ]
    }
   ],
   "source": [
    "context_relevance(bot, \"5yo M, viral triggered asthma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feffa5be-acaa-4a9e-bb05-456b47c18b9b",
   "metadata": {},
   "source": [
    "## Ground truth checker\n",
    "** LLM gives different evaluation each time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c2a8f8bc-5f7e-49a6-a636-598a2694ecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# Data model\n",
    "class GroundTruth(BaseModel):\n",
    "    \"\"\"List facts in handout not based on ground truth\"\"\"\n",
    "    list_of_false: List[str] = Field(description=\"List of facts in handout not based on ground truth\")\n",
    "\n",
    "# LLM with function call \n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GroundTruth)\n",
    "\n",
    "# Prompt \n",
    "system = \"\"\"\n",
    "You are an expert assessor tasked with evaluating whether the generated text (provided by the user between the XML tags GENERATED TEXT) is factually based on the provided context (provided by the user between the XML tags CONTEXT).  \n",
    "\n",
    "Follow these steps:\n",
    "    Step 1: Read the provided context carefully. Understand the information presented in the context.\n",
    "    Step 2: Analyze each sentence in the GENERATED TEXT. Compare it with the provided CONTEXT to determine its factual basis. Sentences in the GENERATED TEXT that are similar (but not verbatim) to the sentences in provided CONTEXT, but are still factually aligned are considered factually based on the CONTEXT.\n",
    "    Step 3: Identify sentences in the GENERATED TEXT that are not factually based on the context (not factually supported by the provided CONTEXT or directly contradicts the provided CONTEXT.) \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "human = \"\"\"\n",
    "<GENERATED TEXT>\n",
    "{handout} \n",
    "</GENERATED TEXT>\n",
    "\n",
    "<CONTEXT>\n",
    "{contexts}\n",
    "</CONTEXT>\n",
    "\"\"\"\n",
    "\n",
    "prompt_groundtruth = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", human),\n",
    "    ]\n",
    ")\n",
    "\n",
    "grader_groundtruth = prompt_groundtruth | structured_llm_grader\n",
    "\n",
    "def tmp(inputs) -> dict:\n",
    "    return inputs\n",
    "\n",
    "def grade_groundtruth(run, example):\n",
    "    result = grader_groundtruth.invoke({\"handout\": example.inputs[\"handout\"], \"contexts\": example.inputs[\"contexts\"]}).list_of_false\n",
    "    count = len(result)\n",
    "    \n",
    "    return {\n",
    "        \"key\": \"count\", \"score\": count, \"comment\": \"num infactual sentences\",\n",
    "        \"sentences\": result\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6b4ec3cb-0292-4f9b-98a7-61f7713650e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_groundtruth(handout, context, dataset_name):\n",
    "    \"\"\"Takes handout and contexts used to make a dataset\"\"\"\n",
    "    client = langsmith.Client()\n",
    "    \n",
    "    dataset = client.create_dataset(\n",
    "        dataset_name=dataset_name,\n",
    "        description=f\"Test whether handout for {diagnosis} is based on provided context\",\n",
    "    )\n",
    "\n",
    "    # **Preprocess context to remove headings\n",
    "    client.create_examples(\n",
    "        inputs=[{\"handout\": handout, \"contexts\": contexts}],\n",
    "        dataset_id=dataset.id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a281f1ae-a83f-4f24-86f1-7c3c57a3e026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_groundtruth(rag_bot, assessment, md_plan):\n",
    "    \"\"\"\n",
    "    retrieved = rag_bot.retrieval_steps(assessment) # dict of query:context\n",
    "    context_dict = retrieved[\"contexts\"]\n",
    "    diagnosis = retrieved[\"diagnosis\"]\n",
    "    \"\"\"\n",
    "    #outputs = rag_bot.make_handout(assessment, md_plan)\n",
    "    #dataset_name = f\"Groundtruth_{diagnosis}\"\n",
    "    #create_dataset_relevance(diagnosis, context_dict, dataset_name=f\"Queries_Docs_{diagnosis}\") # also makes a dataset for retrieval relevance but not evaluate on it\n",
    "    #create_dataset_groundtruth(outputs[\"handout\"], outputs[\"contexts\"], dataset_name)\n",
    "\n",
    "\n",
    "    # tmp - using existing context ground truth to test the llm evaluator\n",
    "    dataset_name = \"Context_groundtruth\"\n",
    "        \n",
    "    evaluate(\n",
    "        lambda x:x,\n",
    "        data=dataset_name,\n",
    "        evaluators=[grade_groundtruth],\n",
    "        experiment_prefix=\"Groundtruth-\",\n",
    "        metadata={\n",
    "            \"model\": \"oai\",\n",
    "            \"diagnosis\":\"tmp\"\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f83d873d-af74-49f6-adb3-cd517015feb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'Groundtruth--091700f9' at:\n",
      "https://smith.langchain.com/o/edfbc8bb-c3a3-5c1e-8b48-11b5a8cfd8ac/datasets/8c0209e9-1fa7-4eae-9ee6-657491c07e75/compare?selectedSessions=71f30369-3ab9-4fab-97ad-34e61d6e4790\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d9022184ba457fbe50ed686f8133ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "context_groundtruth(bot, None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fc3492-d5e1-426e-9428-01d2083cd48e",
   "metadata": {},
   "source": [
    "## LLM grading based on custom metrics\n",
    "- jargon\n",
    "- reference list\n",
    "- template format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5a519e-40f6-4cfd-b9f9-27cf48252fa7",
   "metadata": {},
   "source": [
    "## Human feedback of output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d593e441-f1d7-4521-96a2-ca060923a33d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
